{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a55c0cb-6337-4f53-8bbe-60a08b27094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac97220b-36f6-4a9d-8004-c3a7f04bfbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "      <th>bought_insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  affordibility  bought_insurance\n",
       "0   22              1                 0\n",
       "1   25              0                 0\n",
       "2   47              1                 1\n",
       "3   52              0                 0\n",
       "4   46              1                 1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('insurance_data_deep.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2d2fe68-781a-4c79-805e-aaa071e48cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['age','affordibility']], df.bought_insurance, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcd9d74e-e80e-49f1-9f9d-a291d60ddfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train.copy()\n",
    "X_train_scaled['age'] = X_train_scaled['age'] / 100\n",
    "\n",
    "X_test_scaled = X_test.copy()\n",
    "X_test_scaled['age'] = X_test_scaled['age'] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "375e8f7e-24f5-4aec-846d-ed150af84ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhani\\new_anaconda 3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 981ms/step - accuracy: 0.5000 - loss: 0.7428\n",
      "Epoch 2/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5000 - loss: 0.7424\n",
      "Epoch 3/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5000 - loss: 0.7420\n",
      "Epoch 4/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5000 - loss: 0.7416\n",
      "Epoch 5/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.5000 - loss: 0.7411\n",
      "Epoch 6/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5000 - loss: 0.7407\n",
      "Epoch 7/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5000 - loss: 0.7403\n",
      "Epoch 8/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5000 - loss: 0.7399\n",
      "Epoch 9/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5000 - loss: 0.7395\n",
      "Epoch 10/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5000 - loss: 0.7390\n",
      "Epoch 11/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5000 - loss: 0.7386\n",
      "Epoch 12/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5000 - loss: 0.7382\n",
      "Epoch 13/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5000 - loss: 0.7378\n",
      "Epoch 14/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5000 - loss: 0.7374\n",
      "Epoch 15/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5000 - loss: 0.7370\n",
      "Epoch 16/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5000 - loss: 0.7366\n",
      "Epoch 17/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5000 - loss: 0.7361\n",
      "Epoch 18/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5000 - loss: 0.7357\n",
      "Epoch 19/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5000 - loss: 0.7353\n",
      "Epoch 20/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5000 - loss: 0.7349\n",
      "Epoch 21/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5000 - loss: 0.7345\n",
      "Epoch 22/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5000 - loss: 0.7341\n",
      "Epoch 23/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5000 - loss: 0.7337\n",
      "Epoch 24/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5000 - loss: 0.7333\n",
      "Epoch 25/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5000 - loss: 0.7329\n",
      "Epoch 26/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5000 - loss: 0.7325\n",
      "Epoch 27/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5000 - loss: 0.7321\n",
      "Epoch 28/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.5000 - loss: 0.7317\n",
      "Epoch 29/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5000 - loss: 0.7313\n",
      "Epoch 30/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5000 - loss: 0.7309\n",
      "Epoch 31/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5000 - loss: 0.7305\n",
      "Epoch 32/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5000 - loss: 0.7301\n",
      "Epoch 33/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5000 - loss: 0.7297\n",
      "Epoch 34/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5000 - loss: 0.7293\n",
      "Epoch 35/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5000 - loss: 0.7289\n",
      "Epoch 36/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5000 - loss: 0.7285\n",
      "Epoch 37/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5000 - loss: 0.7281\n",
      "Epoch 38/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5000 - loss: 0.7277\n",
      "Epoch 39/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5000 - loss: 0.7274\n",
      "Epoch 40/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.5000 - loss: 0.7270\n",
      "Epoch 41/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5000 - loss: 0.7266\n",
      "Epoch 42/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5000 - loss: 0.7262\n",
      "Epoch 43/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5000 - loss: 0.7258\n",
      "Epoch 44/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5000 - loss: 0.7254\n",
      "Epoch 45/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5000 - loss: 0.7250\n",
      "Epoch 46/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5000 - loss: 0.7247\n",
      "Epoch 47/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5000 - loss: 0.7243\n",
      "Epoch 48/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5000 - loss: 0.7239\n",
      "Epoch 49/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5000 - loss: 0.7235\n",
      "Epoch 50/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5000 - loss: 0.7232\n",
      "Epoch 51/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.5000 - loss: 0.7228\n",
      "Epoch 52/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5000 - loss: 0.7224\n",
      "Epoch 53/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5000 - loss: 0.7220\n",
      "Epoch 54/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5000 - loss: 0.7217\n",
      "Epoch 55/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5000 - loss: 0.7213\n",
      "Epoch 56/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5000 - loss: 0.7209\n",
      "Epoch 57/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.5000 - loss: 0.7206\n",
      "Epoch 58/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5000 - loss: 0.7202\n",
      "Epoch 59/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5000 - loss: 0.7198\n",
      "Epoch 60/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5000 - loss: 0.7195\n",
      "Epoch 61/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5000 - loss: 0.7191\n",
      "Epoch 62/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5000 - loss: 0.7187\n",
      "Epoch 63/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5000 - loss: 0.7184\n",
      "Epoch 64/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5000 - loss: 0.7180\n",
      "Epoch 65/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5000 - loss: 0.7177\n",
      "Epoch 66/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.5000 - loss: 0.7173\n",
      "Epoch 67/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5000 - loss: 0.7169\n",
      "Epoch 68/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5000 - loss: 0.7166\n",
      "Epoch 69/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5000 - loss: 0.7162\n",
      "Epoch 70/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5000 - loss: 0.7159\n",
      "Epoch 71/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5000 - loss: 0.7155\n",
      "Epoch 72/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5000 - loss: 0.7152\n",
      "Epoch 73/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5000 - loss: 0.7148\n",
      "Epoch 74/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.5000 - loss: 0.7145\n",
      "Epoch 75/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5000 - loss: 0.7141\n",
      "Epoch 76/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5000 - loss: 0.7138\n",
      "Epoch 77/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5000 - loss: 0.7134\n",
      "Epoch 78/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5000 - loss: 0.7131\n",
      "Epoch 79/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.5000 - loss: 0.7128\n",
      "Epoch 80/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5000 - loss: 0.7124\n",
      "Epoch 81/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.5000 - loss: 0.7121\n",
      "Epoch 82/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.5000 - loss: 0.7117\n",
      "Epoch 83/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.5000 - loss: 0.7114\n",
      "Epoch 84/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.5000 - loss: 0.7111\n",
      "Epoch 85/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5000 - loss: 0.7107\n",
      "Epoch 86/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.5000 - loss: 0.7104\n",
      "Epoch 87/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.5000 - loss: 0.7101\n",
      "Epoch 88/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5000 - loss: 0.7097\n",
      "Epoch 89/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5000 - loss: 0.7094\n",
      "Epoch 90/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.5000 - loss: 0.7091\n",
      "Epoch 91/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.5000 - loss: 0.7087\n",
      "Epoch 92/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.5000 - loss: 0.7084\n",
      "Epoch 93/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.5000 - loss: 0.7081\n",
      "Epoch 94/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.5000 - loss: 0.7077\n",
      "Epoch 95/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5000 - loss: 0.7074\n",
      "Epoch 96/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5000 - loss: 0.7071\n",
      "Epoch 97/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5000 - loss: 0.7068\n",
      "Epoch 98/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5000 - loss: 0.7065\n",
      "Epoch 99/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.5000 - loss: 0.7061\n",
      "Epoch 100/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5000 - loss: 0.7058\n",
      "Epoch 101/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5000 - loss: 0.7055\n",
      "Epoch 102/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5000 - loss: 0.7052\n",
      "Epoch 103/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.5000 - loss: 0.7049\n",
      "Epoch 104/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5000 - loss: 0.7045\n",
      "Epoch 105/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5000 - loss: 0.7042\n",
      "Epoch 106/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5000 - loss: 0.7039\n",
      "Epoch 107/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5000 - loss: 0.7036\n",
      "Epoch 108/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5000 - loss: 0.7033\n",
      "Epoch 109/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5000 - loss: 0.7030\n",
      "Epoch 110/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5000 - loss: 0.7027\n",
      "Epoch 111/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5000 - loss: 0.7024\n",
      "Epoch 112/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.5000 - loss: 0.7021\n",
      "Epoch 113/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.5000 - loss: 0.7018\n",
      "Epoch 114/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.5000 - loss: 0.7014\n",
      "Epoch 115/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5000 - loss: 0.7011\n",
      "Epoch 116/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5000 - loss: 0.7008\n",
      "Epoch 117/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5000 - loss: 0.7005\n",
      "Epoch 118/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.5000 - loss: 0.7002\n",
      "Epoch 119/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5000 - loss: 0.6999\n",
      "Epoch 120/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5000 - loss: 0.6996\n",
      "Epoch 121/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5000 - loss: 0.6993\n",
      "Epoch 122/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5000 - loss: 0.6991\n",
      "Epoch 123/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5000 - loss: 0.6988\n",
      "Epoch 124/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.5000 - loss: 0.6985\n",
      "Epoch 125/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5000 - loss: 0.6982\n",
      "Epoch 126/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5000 - loss: 0.6979\n",
      "Epoch 127/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5000 - loss: 0.6976\n",
      "Epoch 128/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5000 - loss: 0.6973\n",
      "Epoch 129/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5000 - loss: 0.6970\n",
      "Epoch 130/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5000 - loss: 0.6967\n",
      "Epoch 131/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5000 - loss: 0.6964\n",
      "Epoch 132/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.5000 - loss: 0.6962\n",
      "Epoch 133/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5000 - loss: 0.6959\n",
      "Epoch 134/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5000 - loss: 0.6956\n",
      "Epoch 135/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5000 - loss: 0.6953\n",
      "Epoch 136/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.5000 - loss: 0.6950\n",
      "Epoch 137/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5000 - loss: 0.6947\n",
      "Epoch 138/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5000 - loss: 0.6945\n",
      "Epoch 139/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5000 - loss: 0.6942\n",
      "Epoch 140/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5000 - loss: 0.6939\n",
      "Epoch 141/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.5000 - loss: 0.6936\n",
      "Epoch 142/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5000 - loss: 0.6934\n",
      "Epoch 143/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.5000 - loss: 0.6931\n",
      "Epoch 144/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5000 - loss: 0.6928\n",
      "Epoch 145/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5000 - loss: 0.6925\n",
      "Epoch 146/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.5000 - loss: 0.6923\n",
      "Epoch 147/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5000 - loss: 0.6920\n",
      "Epoch 148/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5000 - loss: 0.6917\n",
      "Epoch 149/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5000 - loss: 0.6915\n",
      "Epoch 150/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5000 - loss: 0.6912\n",
      "Epoch 151/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5000 - loss: 0.6909\n",
      "Epoch 152/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5000 - loss: 0.6907\n",
      "Epoch 153/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5000 - loss: 0.6904\n",
      "Epoch 154/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5000 - loss: 0.6901\n",
      "Epoch 155/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5000 - loss: 0.6899\n",
      "Epoch 156/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5000 - loss: 0.6896\n",
      "Epoch 157/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.5000 - loss: 0.6894\n",
      "Epoch 158/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5000 - loss: 0.6891\n",
      "Epoch 159/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5000 - loss: 0.6888\n",
      "Epoch 160/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5000 - loss: 0.6886\n",
      "Epoch 161/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5000 - loss: 0.6883\n",
      "Epoch 162/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5000 - loss: 0.6881\n",
      "Epoch 163/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5000 - loss: 0.6878\n",
      "Epoch 164/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5000 - loss: 0.6876\n",
      "Epoch 165/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5000 - loss: 0.6873\n",
      "Epoch 166/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5000 - loss: 0.6871\n",
      "Epoch 167/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.5000 - loss: 0.6868\n",
      "Epoch 168/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5000 - loss: 0.6866\n",
      "Epoch 169/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5000 - loss: 0.6863\n",
      "Epoch 170/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5000 - loss: 0.6861\n",
      "Epoch 171/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5000 - loss: 0.6858\n",
      "Epoch 172/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5000 - loss: 0.6856\n",
      "Epoch 173/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5455 - loss: 0.6853\n",
      "Epoch 174/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5455 - loss: 0.6851\n",
      "Epoch 175/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5455 - loss: 0.6848\n",
      "Epoch 176/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5455 - loss: 0.6846\n",
      "Epoch 177/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.5455 - loss: 0.6844\n",
      "Epoch 178/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5455 - loss: 0.6841\n",
      "Epoch 179/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5455 - loss: 0.6839\n",
      "Epoch 180/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5455 - loss: 0.6836\n",
      "Epoch 181/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5455 - loss: 0.6834\n",
      "Epoch 182/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5455 - loss: 0.6832\n",
      "Epoch 183/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5455 - loss: 0.6829\n",
      "Epoch 184/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5455 - loss: 0.6827\n",
      "Epoch 185/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5455 - loss: 0.6825\n",
      "Epoch 186/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5455 - loss: 0.6822\n",
      "Epoch 187/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.5455 - loss: 0.6820\n",
      "Epoch 188/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5455 - loss: 0.6818\n",
      "Epoch 189/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5455 - loss: 0.6816\n",
      "Epoch 190/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5455 - loss: 0.6813\n",
      "Epoch 191/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5455 - loss: 0.6811\n",
      "Epoch 192/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5455 - loss: 0.6809\n",
      "Epoch 193/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5455 - loss: 0.6806\n",
      "Epoch 194/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5455 - loss: 0.6804\n",
      "Epoch 195/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5455 - loss: 0.6802\n",
      "Epoch 196/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5455 - loss: 0.6800\n",
      "Epoch 197/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.5455 - loss: 0.6798\n",
      "Epoch 198/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5455 - loss: 0.6795\n",
      "Epoch 199/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5455 - loss: 0.6793\n",
      "Epoch 200/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5455 - loss: 0.6791\n",
      "Epoch 201/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5455 - loss: 0.6789\n",
      "Epoch 202/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5455 - loss: 0.6787\n",
      "Epoch 203/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5455 - loss: 0.6784\n",
      "Epoch 204/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5455 - loss: 0.6782\n",
      "Epoch 205/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5455 - loss: 0.6780\n",
      "Epoch 206/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5455 - loss: 0.6778\n",
      "Epoch 207/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.5455 - loss: 0.6776\n",
      "Epoch 208/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5455 - loss: 0.6774\n",
      "Epoch 209/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5455 - loss: 0.6772\n",
      "Epoch 210/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5455 - loss: 0.6770\n",
      "Epoch 211/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.5455 - loss: 0.6768\n",
      "Epoch 212/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.5455 - loss: 0.6765\n",
      "Epoch 213/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - accuracy: 0.5455 - loss: 0.6763\n",
      "Epoch 214/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576ms/step - accuracy: 0.5455 - loss: 0.6761\n",
      "Epoch 215/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.5455 - loss: 0.6759\n",
      "Epoch 216/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.5455 - loss: 0.6757\n",
      "Epoch 217/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.5455 - loss: 0.6755\n",
      "Epoch 218/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.5455 - loss: 0.6753\n",
      "Epoch 219/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.5455 - loss: 0.6751\n",
      "Epoch 220/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5455 - loss: 0.6749\n",
      "Epoch 221/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.5455 - loss: 0.6747\n",
      "Epoch 222/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.5455 - loss: 0.6745\n",
      "Epoch 223/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.5455 - loss: 0.6743\n",
      "Epoch 224/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.5455 - loss: 0.6741\n",
      "Epoch 225/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.5455 - loss: 0.6739\n",
      "Epoch 226/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.5455 - loss: 0.6737\n",
      "Epoch 227/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.5455 - loss: 0.6735\n",
      "Epoch 228/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.5455 - loss: 0.6733\n",
      "Epoch 229/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.5455 - loss: 0.6731\n",
      "Epoch 230/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.5455 - loss: 0.6730\n",
      "Epoch 231/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5455 - loss: 0.6728\n",
      "Epoch 232/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5455 - loss: 0.6726\n",
      "Epoch 233/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5455 - loss: 0.6724\n",
      "Epoch 234/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.5455 - loss: 0.6722\n",
      "Epoch 235/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5455 - loss: 0.6720\n",
      "Epoch 236/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5455 - loss: 0.6718\n",
      "Epoch 237/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5455 - loss: 0.6716\n",
      "Epoch 238/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5455 - loss: 0.6714\n",
      "Epoch 239/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5455 - loss: 0.6713\n",
      "Epoch 240/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5455 - loss: 0.6711\n",
      "Epoch 241/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5455 - loss: 0.6709\n",
      "Epoch 242/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5455 - loss: 0.6707\n",
      "Epoch 243/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5455 - loss: 0.6705\n",
      "Epoch 244/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.5455 - loss: 0.6703\n",
      "Epoch 245/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5455 - loss: 0.6702\n",
      "Epoch 246/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5455 - loss: 0.6700\n",
      "Epoch 247/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5455 - loss: 0.6698\n",
      "Epoch 248/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5455 - loss: 0.6696\n",
      "Epoch 249/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5455 - loss: 0.6695\n",
      "Epoch 250/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5455 - loss: 0.6693\n",
      "Epoch 251/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5455 - loss: 0.6691\n",
      "Epoch 252/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5455 - loss: 0.6689\n",
      "Epoch 253/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5455 - loss: 0.6688\n",
      "Epoch 254/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5455 - loss: 0.6686\n",
      "Epoch 255/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5455 - loss: 0.6684\n",
      "Epoch 256/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5455 - loss: 0.6682\n",
      "Epoch 257/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.5455 - loss: 0.6681\n",
      "Epoch 258/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.5909 - loss: 0.6679\n",
      "Epoch 259/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.5909 - loss: 0.6677\n",
      "Epoch 260/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.5909 - loss: 0.6676\n",
      "Epoch 261/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.5909 - loss: 0.6674\n",
      "Epoch 262/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5909 - loss: 0.6672\n",
      "Epoch 263/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5909 - loss: 0.6671\n",
      "Epoch 264/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5909 - loss: 0.6669\n",
      "Epoch 265/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.5909 - loss: 0.6667\n",
      "Epoch 266/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5909 - loss: 0.6666\n",
      "Epoch 267/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.5909 - loss: 0.6664\n",
      "Epoch 268/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.5909 - loss: 0.6662\n",
      "Epoch 269/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.5909 - loss: 0.6661\n",
      "Epoch 270/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5909 - loss: 0.6659\n",
      "Epoch 271/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.5909 - loss: 0.6658\n",
      "Epoch 272/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5909 - loss: 0.6656\n",
      "Epoch 273/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5909 - loss: 0.6654\n",
      "Epoch 274/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5909 - loss: 0.6653\n",
      "Epoch 275/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5909 - loss: 0.6651\n",
      "Epoch 276/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5909 - loss: 0.6650\n",
      "Epoch 277/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5909 - loss: 0.6648\n",
      "Epoch 278/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5909 - loss: 0.6647\n",
      "Epoch 279/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.5909 - loss: 0.6645\n",
      "Epoch 280/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5909 - loss: 0.6644\n",
      "Epoch 281/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5909 - loss: 0.6642\n",
      "Epoch 282/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5909 - loss: 0.6640\n",
      "Epoch 283/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.5909 - loss: 0.6639\n",
      "Epoch 284/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - accuracy: 0.5909 - loss: 0.6637\n",
      "Epoch 285/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.5909 - loss: 0.6636\n",
      "Epoch 286/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.5909 - loss: 0.6634\n",
      "Epoch 287/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.5909 - loss: 0.6633\n",
      "Epoch 288/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.5909 - loss: 0.6632\n",
      "Epoch 289/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.5909 - loss: 0.6630\n",
      "Epoch 290/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.5909 - loss: 0.6629\n",
      "Epoch 291/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5909 - loss: 0.6627\n",
      "Epoch 292/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5909 - loss: 0.6626\n",
      "Epoch 293/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.5909 - loss: 0.6624\n",
      "Epoch 294/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5909 - loss: 0.6623\n",
      "Epoch 295/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.5909 - loss: 0.6621\n",
      "Epoch 296/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.5909 - loss: 0.6620\n",
      "Epoch 297/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.5909 - loss: 0.6618\n",
      "Epoch 298/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.5909 - loss: 0.6617\n",
      "Epoch 299/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.5909 - loss: 0.6616\n",
      "Epoch 300/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.5909 - loss: 0.6614\n",
      "Epoch 301/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.5909 - loss: 0.6613\n",
      "Epoch 302/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5909 - loss: 0.6612\n",
      "Epoch 303/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5909 - loss: 0.6610\n",
      "Epoch 304/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5909 - loss: 0.6609\n",
      "Epoch 305/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5909 - loss: 0.6607\n",
      "Epoch 306/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5909 - loss: 0.6606\n",
      "Epoch 307/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5909 - loss: 0.6605\n",
      "Epoch 308/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5909 - loss: 0.6603\n",
      "Epoch 309/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5909 - loss: 0.6602\n",
      "Epoch 310/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5909 - loss: 0.6601\n",
      "Epoch 311/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5909 - loss: 0.6599\n",
      "Epoch 312/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5909 - loss: 0.6598\n",
      "Epoch 313/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5909 - loss: 0.6597\n",
      "Epoch 314/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5909 - loss: 0.6595\n",
      "Epoch 315/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5909 - loss: 0.6594\n",
      "Epoch 316/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5909 - loss: 0.6593\n",
      "Epoch 317/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5909 - loss: 0.6591\n",
      "Epoch 318/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5909 - loss: 0.6590\n",
      "Epoch 319/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5909 - loss: 0.6589\n",
      "Epoch 320/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5909 - loss: 0.6588\n",
      "Epoch 321/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5909 - loss: 0.6586\n",
      "Epoch 322/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5909 - loss: 0.6585\n",
      "Epoch 323/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5909 - loss: 0.6584\n",
      "Epoch 324/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5909 - loss: 0.6583\n",
      "Epoch 325/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5909 - loss: 0.6581\n",
      "Epoch 326/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5909 - loss: 0.6580\n",
      "Epoch 327/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5909 - loss: 0.6579\n",
      "Epoch 328/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5909 - loss: 0.6578\n",
      "Epoch 329/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5909 - loss: 0.6576\n",
      "Epoch 330/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5909 - loss: 0.6575\n",
      "Epoch 331/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5909 - loss: 0.6574\n",
      "Epoch 332/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5909 - loss: 0.6573\n",
      "Epoch 333/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5909 - loss: 0.6572\n",
      "Epoch 334/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5909 - loss: 0.6570\n",
      "Epoch 335/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5909 - loss: 0.6569\n",
      "Epoch 336/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5909 - loss: 0.6568\n",
      "Epoch 337/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5909 - loss: 0.6567\n",
      "Epoch 338/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5909 - loss: 0.6566\n",
      "Epoch 339/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5909 - loss: 0.6565\n",
      "Epoch 340/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5909 - loss: 0.6563\n",
      "Epoch 341/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5909 - loss: 0.6562\n",
      "Epoch 342/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5909 - loss: 0.6561\n",
      "Epoch 343/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5909 - loss: 0.6560\n",
      "Epoch 344/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5909 - loss: 0.6559\n",
      "Epoch 345/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5909 - loss: 0.6558\n",
      "Epoch 346/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5909 - loss: 0.6557\n",
      "Epoch 347/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5909 - loss: 0.6555\n",
      "Epoch 348/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5909 - loss: 0.6554\n",
      "Epoch 349/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5909 - loss: 0.6553\n",
      "Epoch 350/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5909 - loss: 0.6552\n",
      "Epoch 351/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5909 - loss: 0.6551\n",
      "Epoch 352/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5909 - loss: 0.6550\n",
      "Epoch 353/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5909 - loss: 0.6549\n",
      "Epoch 354/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5909 - loss: 0.6548\n",
      "Epoch 355/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.5909 - loss: 0.6547\n",
      "Epoch 356/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5909 - loss: 0.6546\n",
      "Epoch 357/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5909 - loss: 0.6545\n",
      "Epoch 358/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5909 - loss: 0.6543\n",
      "Epoch 359/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5909 - loss: 0.6542\n",
      "Epoch 360/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5909 - loss: 0.6541\n",
      "Epoch 361/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5909 - loss: 0.6540\n",
      "Epoch 362/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.5909 - loss: 0.6539\n",
      "Epoch 363/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.5909 - loss: 0.6538\n",
      "Epoch 364/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.5909 - loss: 0.6537\n",
      "Epoch 365/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.5909 - loss: 0.6536\n",
      "Epoch 366/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.5909 - loss: 0.6535\n",
      "Epoch 367/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5909 - loss: 0.6534\n",
      "Epoch 368/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.5909 - loss: 0.6533\n",
      "Epoch 369/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.5909 - loss: 0.6532\n",
      "Epoch 370/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.5909 - loss: 0.6531\n",
      "Epoch 371/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5909 - loss: 0.6530\n",
      "Epoch 372/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.5909 - loss: 0.6529\n",
      "Epoch 373/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.5909 - loss: 0.6528\n",
      "Epoch 374/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5909 - loss: 0.6527\n",
      "Epoch 375/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.5909 - loss: 0.6526\n",
      "Epoch 376/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.5909 - loss: 0.6525\n",
      "Epoch 377/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.5909 - loss: 0.6524\n",
      "Epoch 378/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.5909 - loss: 0.6523\n",
      "Epoch 379/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.5909 - loss: 0.6522\n",
      "Epoch 380/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.5909 - loss: 0.6521\n",
      "Epoch 381/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.5909 - loss: 0.6520\n",
      "Epoch 382/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.5909 - loss: 0.6519\n",
      "Epoch 383/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5909 - loss: 0.6518\n",
      "Epoch 384/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.5909 - loss: 0.6517\n",
      "Epoch 385/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.5909 - loss: 0.6517\n",
      "Epoch 386/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.5909 - loss: 0.6516\n",
      "Epoch 387/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.5909 - loss: 0.6515\n",
      "Epoch 388/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.5909 - loss: 0.6514\n",
      "Epoch 389/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.5909 - loss: 0.6513\n",
      "Epoch 390/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5909 - loss: 0.6512\n",
      "Epoch 391/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5909 - loss: 0.6511\n",
      "Epoch 392/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5909 - loss: 0.6510\n",
      "Epoch 393/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5909 - loss: 0.6509\n",
      "Epoch 394/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5909 - loss: 0.6508\n",
      "Epoch 395/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5909 - loss: 0.6507\n",
      "Epoch 396/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5909 - loss: 0.6506\n",
      "Epoch 397/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5909 - loss: 0.6506\n",
      "Epoch 398/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5909 - loss: 0.6505\n",
      "Epoch 399/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5909 - loss: 0.6504\n",
      "Epoch 400/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5909 - loss: 0.6503\n",
      "Epoch 401/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5909 - loss: 0.6502\n",
      "Epoch 402/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5909 - loss: 0.6501\n",
      "Epoch 403/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.5909 - loss: 0.6500\n",
      "Epoch 404/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5909 - loss: 0.6499\n",
      "Epoch 405/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5909 - loss: 0.6499\n",
      "Epoch 406/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5909 - loss: 0.6498\n",
      "Epoch 407/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5909 - loss: 0.6497\n",
      "Epoch 408/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5909 - loss: 0.6496\n",
      "Epoch 409/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5909 - loss: 0.6495\n",
      "Epoch 410/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.5909 - loss: 0.6494\n",
      "Epoch 411/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5909 - loss: 0.6494\n",
      "Epoch 412/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.5909 - loss: 0.6493\n",
      "Epoch 413/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.5909 - loss: 0.6492\n",
      "Epoch 414/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.5909 - loss: 0.6491\n",
      "Epoch 415/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.5909 - loss: 0.6490\n",
      "Epoch 416/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.5909 - loss: 0.6489\n",
      "Epoch 417/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5909 - loss: 0.6489\n",
      "Epoch 418/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.5909 - loss: 0.6488\n",
      "Epoch 419/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.5909 - loss: 0.6487\n",
      "Epoch 420/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.5909 - loss: 0.6486\n",
      "Epoch 421/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.5909 - loss: 0.6485\n",
      "Epoch 422/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5909 - loss: 0.6485\n",
      "Epoch 423/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.5909 - loss: 0.6484\n",
      "Epoch 424/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.5909 - loss: 0.6483\n",
      "Epoch 425/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.5909 - loss: 0.6482\n",
      "Epoch 426/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.5909 - loss: 0.6481\n",
      "Epoch 427/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5909 - loss: 0.6481\n",
      "Epoch 428/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.5909 - loss: 0.6480\n",
      "Epoch 429/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.5909 - loss: 0.6479\n",
      "Epoch 430/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5909 - loss: 0.6478\n",
      "Epoch 431/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5909 - loss: 0.6478\n",
      "Epoch 432/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5909 - loss: 0.6477\n",
      "Epoch 433/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5909 - loss: 0.6476\n",
      "Epoch 434/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5909 - loss: 0.6475\n",
      "Epoch 435/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5909 - loss: 0.6475\n",
      "Epoch 436/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.5909 - loss: 0.6474\n",
      "Epoch 437/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5909 - loss: 0.6473\n",
      "Epoch 438/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.5909 - loss: 0.6472\n",
      "Epoch 439/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.5909 - loss: 0.6472\n",
      "Epoch 440/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.5909 - loss: 0.6471\n",
      "Epoch 441/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.5909 - loss: 0.6470\n",
      "Epoch 442/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5909 - loss: 0.6469\n",
      "Epoch 443/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.5909 - loss: 0.6469\n",
      "Epoch 444/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5909 - loss: 0.6468\n",
      "Epoch 445/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5909 - loss: 0.6467\n",
      "Epoch 446/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.5909 - loss: 0.6466\n",
      "Epoch 447/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5909 - loss: 0.6466\n",
      "Epoch 448/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5909 - loss: 0.6465\n",
      "Epoch 449/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5909 - loss: 0.6464\n",
      "Epoch 450/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5909 - loss: 0.6464\n",
      "Epoch 451/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5909 - loss: 0.6463\n",
      "Epoch 452/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5909 - loss: 0.6462\n",
      "Epoch 453/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5909 - loss: 0.6462\n",
      "Epoch 454/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5909 - loss: 0.6461\n",
      "Epoch 455/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.5909 - loss: 0.6460\n",
      "Epoch 456/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5909 - loss: 0.6459\n",
      "Epoch 457/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5909 - loss: 0.6459\n",
      "Epoch 458/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.5909 - loss: 0.6458\n",
      "Epoch 459/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.5909 - loss: 0.6457\n",
      "Epoch 460/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.5909 - loss: 0.6457\n",
      "Epoch 461/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.5909 - loss: 0.6456\n",
      "Epoch 462/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.5909 - loss: 0.6455\n",
      "Epoch 463/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.5909 - loss: 0.6455\n",
      "Epoch 464/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.5909 - loss: 0.6454\n",
      "Epoch 465/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.5909 - loss: 0.6453\n",
      "Epoch 466/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.5909 - loss: 0.6453\n",
      "Epoch 467/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.5909 - loss: 0.6452\n",
      "Epoch 468/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.5909 - loss: 0.6451\n",
      "Epoch 469/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.5909 - loss: 0.6451\n",
      "Epoch 470/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.5909 - loss: 0.6450\n",
      "Epoch 471/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.5909 - loss: 0.6449\n",
      "Epoch 472/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5909 - loss: 0.6449\n",
      "Epoch 473/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5909 - loss: 0.6448\n",
      "Epoch 474/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5909 - loss: 0.6447\n",
      "Epoch 475/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.5909 - loss: 0.6447\n",
      "Epoch 476/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5909 - loss: 0.6446\n",
      "Epoch 477/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5909 - loss: 0.6445\n",
      "Epoch 478/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5909 - loss: 0.6445\n",
      "Epoch 479/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5909 - loss: 0.6444\n",
      "Epoch 480/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5909 - loss: 0.6444\n",
      "Epoch 481/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5909 - loss: 0.6443\n",
      "Epoch 482/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5909 - loss: 0.6442\n",
      "Epoch 483/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5909 - loss: 0.6442\n",
      "Epoch 484/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5909 - loss: 0.6441\n",
      "Epoch 485/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5909 - loss: 0.6440\n",
      "Epoch 486/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5909 - loss: 0.6440\n",
      "Epoch 487/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5909 - loss: 0.6439\n",
      "Epoch 488/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5909 - loss: 0.6439\n",
      "Epoch 489/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5909 - loss: 0.6438\n",
      "Epoch 490/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5909 - loss: 0.6437\n",
      "Epoch 491/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5909 - loss: 0.6437\n",
      "Epoch 492/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5909 - loss: 0.6436\n",
      "Epoch 493/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5909 - loss: 0.6436\n",
      "Epoch 494/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5909 - loss: 0.6435\n",
      "Epoch 495/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5909 - loss: 0.6434\n",
      "Epoch 496/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.5909 - loss: 0.6434\n",
      "Epoch 497/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5909 - loss: 0.6433\n",
      "Epoch 498/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5909 - loss: 0.6433\n",
      "Epoch 499/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5909 - loss: 0.6432\n",
      "Epoch 500/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5909 - loss: 0.6431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x204092bd400>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(1, input_shape=(2,), activation='sigmoid', kernel_initializer='ones', bias_initializer='zeros')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(X_train_scaled, y_train, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2be5ff2-df78-4322-95d3-49769de2dfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.8333 - loss: 0.5556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5556402206420898, 0.8333333134651184]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6ef081e-169a-48ba-a5a2-d333b32606b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.67331934],\n",
       "       [0.66144764],\n",
       "       [0.67499775],\n",
       "       [0.45126277],\n",
       "       [0.60473907],\n",
       "       [0.4531555 ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9de8a6be-2ecd-4da0-985f-2c3755bfe7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9     1\n",
       "25    1\n",
       "8     1\n",
       "21    0\n",
       "0     0\n",
       "12    0\n",
       "Name: bought_insurance, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d3c00bd-473a-46ff-b612-242f1edd064e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.76406646],\n",
       "        [0.6513832 ]], dtype=float32),\n",
       " array([-0.3942271], dtype=float32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef, intercept = model.get_weights()\n",
    "coef, intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d70115c4-2961-4701-a66a-e8d111551bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    import math\n",
    "    return 1/(1+math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fad3a251-1419-40ab-bf15-0fbb21038bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhani\\AppData\\Local\\Temp\\ipykernel_11484\\1356804808.py:3: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return 1/(1+math.exp(-x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4286753374869888"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pred_function(age, affordibility):\n",
    "    weighted_sum = coef[0]*age + coef[1]*affordibility + intercept\n",
    "    return sigmoid(weighted_sum)\n",
    "\n",
    "pred_function(.14,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27dcdd7c-e5ae-4770-8905-38f25cfc73ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99999386, 0.5       , 0.73105858])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid_numpy(X):\n",
    "    return 1/(1+np.exp(-X))\n",
    "sigmoid_numpy(np.array([12,0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c79a0a3a-d4a6-4505-9b13-af3b53135c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(y_true, y_pred):\n",
    "    epsilon = 1e-15\n",
    "    y_pred_new = [max(i,epsilon) for i in y_pred]\n",
    "    y_pred_new = [min(i, 1-epsilon) for i in y_pred_new]\n",
    "    y_pred_new = np.array(y_pred_new)\n",
    "    return -np.mean(y_true*np.log(y_pred_new) + (1-y_true)*np.log(1-y_pred_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0425f776-f744-4f48-915b-cc2fb3bd216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(age, affordibility, y_true, epochs):\n",
    "    w1 = w2 = 1\n",
    "    bias = 0\n",
    "    rate = 0.5\n",
    "    n = len(age)\n",
    "    for i in range(epochs):\n",
    "        weighted_sum = w1*age + w2*affordibility + bias\n",
    "        y_pred = sigmoid_numpy(weighted_sum)\n",
    "        loss = log_loss(y_true, y_pred)\n",
    "\n",
    "        w1d = (1/n)*np.dot(np.transpose(age),(y_pred-y_true))\n",
    "        w2d = (1/n)*np.dot(np.transpose(affordibility), (y_pred-y_true))\n",
    "\n",
    "        bias_d = np.mean(y_pred - y_true)\n",
    "        w1 = w1 - rate*w1d\n",
    "        w2 = w2 - rate*w2d\n",
    "        bias = bias - rate*bias_d\n",
    "\n",
    "        print(f'Epochs: {i}, w1: {w1}, w2: {w2}, bias: {bias}, loss: {loss}')\n",
    "\n",
    "    return w1, w2, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f186f36-4ff7-4d3f-b6b2-8d24474555a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 0, w1: 0.9736899318847281, w2: 0.931388810977659, bias: -0.11748951666770448, loss: 0.7428288579142563\n",
      "Epochs: 1, w1: 0.9536535852311094, w2: 0.8740290167758512, bias: -0.21881533456146035, loss: 0.7072146449948487\n",
      "Epochs: 2, w1: 0.9393731039296969, w2: 0.8271852202997496, bias: -0.3053620401943441, loss: 0.6814881914786812\n",
      "Epochs: 3, w1: 0.9301932588998061, w2: 0.7897792032048467, bias: -0.37884372361582785, loss: 0.6633428084673968\n",
      "Epochs: 4, w1: 0.9254091137248938, w2: 0.7605726653866934, bias: -0.44108236820018304, loss: 0.650742850709519\n",
      "Epochs: 5, w1: 0.9243325693598607, w2: 0.738313053647322, bias: -0.49384257986251556, loss: 0.6420508089402462\n",
      "Epochs: 6, w1: 0.926333296357235, w2: 0.7218280753843739, bias: -0.5387319906498417, loss: 0.6360356979531208\n",
      "Epochs: 7, w1: 0.930858097563688, w2: 0.7100747303660235, bias: -0.5771558825717441, loss: 0.631816485354411\n",
      "Epochs: 8, w1: 0.9374354910317362, w2: 0.7021560855322683, bias: -0.6103083840841516, loss: 0.6287844495353145\n",
      "Epochs: 9, w1: 0.9456716791005845, w2: 0.6973185496313956, bias: -0.639184616298235, loss: 0.626529442944178\n",
      "Epochs: 10, w1: 0.9552423303850909, w2: 0.6949390905593646, bias: -0.6646027475198829, loss: 0.624779988185889\n",
      "Epochs: 11, w1: 0.9658829303208043, w2: 0.6945084189034805, bias: -0.6872291753319572, loss: 0.6233586375123873\n",
      "Epochs: 12, w1: 0.9773792291739571, w2: 0.6956135754890374, bias: -0.7076031311561145, loss: 0.6221504235399642\n",
      "Epochs: 13, w1: 0.9895585317325278, w2: 0.6979216736079811, bias: -0.7261589451808116, loss: 0.6210813136963943\n",
      "Epochs: 14, w1: 1.0022821152183012, w2: 0.7011655439884263, bias: -0.7432453293938631, loss: 0.6201038296955017\n",
      "Epochs: 15, w1: 1.015438815630551, w2: 0.7051314781630986, bias: -0.7591416308217254, loss: 0.6191875984155962\n",
      "Epochs: 16, w1: 1.0289397023932398, w2: 0.709648985803042, bias: -0.7740712914557775, loss: 0.6183132103318708\n",
      "Epochs: 17, w1: 1.0427137116001344, w2: 0.7145823568137355, bias: -0.7882128634885648, loss: 0.6174682582697213\n",
      "Epochs: 18, w1: 1.056704096120398, w2: 0.7198237783231305, bias: -0.8017089504235339, loss: 0.616644796399796\n",
      "Epochs: 19, w1: 1.0708655573080879, w2: 0.7252877588356242, bias: -0.8146734229312049, loss: 0.61583771667916\n",
      "Epochs: 20, w1: 1.085161937564632, w2: 0.7309066337223022, bias: -0.827197218409105, loss: 0.615043714436491\n",
      "Epochs: 21, w1: 1.0995643699866924, w2: 0.7366269554469955, bias: -0.8393529883341466, loss: 0.6142606306676933\n",
      "Epochs: 22, w1: 1.1140497980199755, w2: 0.7424066021061672, bias: -0.8511988141914534, loss: 0.6134870344622743\n",
      "Epochs: 23, w1: 1.1285997931774339, w2: 0.7482124659467999, bias: -0.8627811738792539, loss: 0.6127219581535038\n",
      "Epochs: 24, w1: 1.1431996120187125, w2: 0.7540186082823849, bias: -0.8741373069609975, loss: 0.6119647294414037\n",
      "Epochs: 25, w1: 1.1578374446869284, w2: 0.7598047883543968, bias: -0.8852970989389227, loss: 0.6112148650157285\n",
      "Epochs: 26, w1: 1.1725038165119064, w2: 0.765555291348178, bias: -0.8962845813945609, loss: 0.6104720031489476\n",
      "Epochs: 27, w1: 1.1871911117453235, w2: 0.7712579953323881, bias: -0.9071191257544718, loss: 0.6097358609684286\n",
      "Epochs: 28, w1: 1.2018931946388465, w2: 0.7769036287786946, bias: -0.9178163929444821, loss: 0.6090062073517919\n",
      "Epochs: 29, w1: 1.21660510804447, w2: 0.7824851799565415, bias: -0.9283890886873851, loss: 0.608282845710547\n",
      "Epochs: 30, w1: 1.2313228337147433, w2: 0.7879974272726737, bias: -0.9388475641432381, loss: 0.6075656030320272\n",
      "Epochs: 31, w1: 1.2460431016880733, w2: 0.7934365658732725, bias: -0.9492002935318158, loss: 0.6068543228826871\n",
      "Epochs: 32, w1: 1.2607632387109597, w2: 0.798799910833712, bias: -0.9594542539318721, loss: 0.6061488609195971\n",
      "Epochs: 33, w1: 1.2754810476990548, w2: 0.8040856612650233, bias: -0.9696152273069788, loss: 0.6054490819908689\n",
      "Epochs: 34, w1: 1.2901947118740469, w2: 0.809292712862935, bias: -0.9796880407059236, loss: 0.6047548582434892\n",
      "Epochs: 35, w1: 1.3049027185161204, w2: 0.8144205089744893, bias: -0.9896767573186839, loss: 0.604066067870647\n",
      "Epochs: 36, w1: 1.3196037983088749, w2: 0.8194689222880243, bias: -0.9995848284688316, loss: 0.6033825942657642\n",
      "Epochs: 37, w1: 1.3342968770787478, w2: 0.8244381608690348, bias: -1.00941521455492, loss: 0.6027043254358909\n",
      "Epochs: 38, w1: 1.3489810373872098, w2: 0.8293286935508275, bias: -1.0191704813088125, loss: 0.6020311535811719\n",
      "Epochs: 39, w1: 1.363655487955702, w2: 0.834141190712067, bias: -1.0288528764316198, loss: 0.6013629747812914\n",
      "Epochs: 40, w1: 1.3783195393179466, w2: 0.8388764772868944, bias: -1.0384643906289521, loss: 0.6006996887514325\n",
      "Epochs: 41, w1: 1.3929725844237943, w2: 0.8435354955001088, bias: -1.048006806241578, loss: 0.6000411986439697\n",
      "Epochs: 42, w1: 1.4076140831806239, w2: 0.8481192753340512, bias: -1.057481736011579, loss: 0.5993874108807854\n",
      "Epochs: 43, w1: 1.4222435501263795, w2: 0.8526289111424995, bias: -1.066890654002851, loss: 0.5987382350065792\n",
      "Epochs: 44, w1: 1.4368605445936513, w2: 0.8570655431517032, bias: -1.0762349202806512, loss: 0.598093583557015\n",
      "Epochs: 45, w1: 1.451464662855574, w2: 0.8614303428468636, bias: -1.0855158006258134, loss: 0.5974533719377464\n",
      "Epochs: 46, w1: 1.466055531848703, w2: 0.8657245014475714, bias: -1.0947344822977763, loss: 0.5968175183117647\n",
      "Epochs: 47, w1: 1.4806328041509813, w2: 0.8699492208388355, bias: -1.103892086652756, loss: 0.5961859434933902\n",
      "Epochs: 48, w1: 1.4951961539588399, w2: 0.874105706454004, bias: -1.1129896792582663, loss: 0.5955585708477928\n",
      "Epochs: 49, w1: 1.509745273859866, w2: 0.8781951617089662, bias: -1.1220282780139241, loss: 0.5949353261952894\n",
      "Epochs: 50, w1: 1.5242798722391318, w2: 0.8822187836689881, bias: -1.1310088596841466, loss: 0.5943161377198863\n",
      "Epochs: 51, w1: 1.538799671190381, w2: 0.8861777596947034, bias: -1.139932365165402, loss: 0.5937009358816897\n",
      "Epochs: 52, w1: 1.5533044048295996, w2: 0.8900732648656113, bias: -1.1487997037447355, loss: 0.5930896533328961\n",
      "Epochs: 53, w1: 1.5677938179294257, w2: 0.8939064600206512, bias: -1.1576117565538497, loss: 0.5924822248371355\n",
      "Epochs: 54, w1: 1.5822676648095038, w2: 0.897678490288208, bias: -1.1663693793813252, loss: 0.5918785871919886\n",
      "Epochs: 55, w1: 1.5967257084311233, w2: 0.9013904840039861, bias: -1.175073404972397, loss: 0.5912786791545124\n",
      "Epochs: 56, w1: 1.6111677196550174, w2: 0.9050435519359378, bias: -1.183724644919323, loss: 0.5906824413696463\n",
      "Epochs: 57, w1: 1.6255934766295703, w2: 0.9086387867519407, bias: -1.1923238912243923, loss: 0.5900898163013606\n",
      "Epochs: 58, w1: 1.6400027642833532, w2: 0.9121772626790611, bias: -1.2008719176009222, loss: 0.5895007481664457\n",
      "Epochs: 59, w1: 1.6543953739012087, w2: 0.9156600353136917, bias: -1.2093694805643016, loss: 0.5889151828708239\n",
      "Epochs: 60, w1: 1.6687711027673287, w2: 0.9190881415501768, bias: -1.2178173203545686, loss: 0.5883330679482884\n",
      "Epochs: 61, w1: 1.6831297538621284, w2: 0.9224625996021641, bias: -1.2262161617235832, loss: 0.587754352501569\n",
      "Epochs: 62, w1: 1.697471135602396, w2: 0.9257844090961933, bias: -1.2345667146131627, loss: 0.5871789871456384\n",
      "Epochs: 63, w1: 1.711795061616327, w2: 0.9290545512212336, bias: -1.242869674745205, loss: 0.5866069239531647\n",
      "Epochs: 64, w1: 1.7261013505467488, w2: 0.9322739889212253, bias: -1.2511257241405795, loss: 0.5860381164020316\n",
      "Epochs: 65, w1: 1.7403898258771897, w2: 0.9354436671203418, bias: -1.2593355315801789, loss: 0.5854725193248443\n",
      "Epochs: 66, w1: 1.7546603157765293, w2: 0.9385645129728113, bias: -1.2674997530188292, loss: 0.5849100888603412\n",
      "Epochs: 67, w1: 1.7689126529588144, w2: 0.9416374361308232, bias: -1.275619031960611, loss: 0.5843507824066418\n",
      "Epochs: 68, w1: 1.7831466745555185, w2: 0.9446633290253916, bias: -1.283693999802426, loss: 0.5837945585762574\n",
      "Epochs: 69, w1: 1.7973622219980594, w2: 0.9476430671561193, bias: -1.2917252761512859, loss: 0.5832413771527942\n",
      "Epochs: 70, w1: 1.8115591409088296, w2: 0.9505775093866567, bias: -1.2997134691197103, loss: 0.5826911990492895\n",
      "Epochs: 71, w1: 1.8257372809993346, w2: 0.9534674982433322, bias: -1.3076591756027507, loss: 0.5821439862681095\n",
      "Epochs: 72, w1: 1.8398964959743167, w2: 0.9563138602149698, bias: -1.3155629815394705, loss: 0.5815997018623559\n",
      "Epochs: 73, w1: 1.854036643440957, w2: 0.9591174060523415, bias: -1.3234254621611543, loss: 0.5810583098987187\n",
      "Epochs: 74, w1: 1.8681575848224263, w2: 0.9618789310660444, bias: -1.3312471822280851, loss: 0.58051977542172\n",
      "Epochs: 75, w1: 1.882259185275198, w2: 0.9645992154218652, bias: -1.3390286962563693, loss: 0.579984064419297\n",
      "Epochs: 76, w1: 1.8963413136096432, w2: 0.9672790244329129, bias: -1.3467705487360144, loss: 0.5794511437896713\n",
      "Epochs: 77, w1: 1.9104038422135232, w2: 0.9699191088479711, bias: -1.354473274341238, loss: 0.5789209813094535\n",
      "Epochs: 78, w1: 1.9244466469780623, w2: 0.972520205135661, bias: -1.3621373981338052, loss: 0.5783935456029389\n",
      "Epochs: 79, w1: 1.9384696072263445, w2: 0.9750830357641133, bias: -1.3697634357600514, loss: 0.5778688061125461\n",
      "Epochs: 80, w1: 1.9524726056438204, w2: 0.9776083094759328, bias: -1.3773518936421296, loss: 0.5773467330703558\n",
      "Epochs: 81, w1: 1.9664555282107485, w2: 0.9800967215583107, bias: -1.3849032691639303, loss: 0.5768272974707069\n",
      "Epochs: 82, w1: 1.9804182641364285, w2: 0.9825489541081905, bias: -1.392418050852049, loss: 0.5763104710438095\n",
      "Epochs: 83, w1: 1.994360705795099, w2: 0.9849656762924378, bias: -1.3998967185521152, loss: 0.5757962262303377\n",
      "Epochs: 84, w1: 2.0082827486634014, w2: 0.9873475446029976, bias: -1.4073397436007509, loss: 0.5752845361569595\n",
      "Epochs: 85, w1: 2.0221842912593204, w2: 0.9896952031070478, bias: -1.4147475889933847, loss: 0.574775374612777\n",
      "Epochs: 86, w1: 2.036065235082525, w2: 0.9920092836921801, bias: -1.422120709548121, loss: 0.5742687160266319\n",
      "Epochs: 87, w1: 2.0499254845560455, w2: 0.9942904063066523, bias: -1.429459552065836, loss: 0.5737645354452513\n",
      "Epochs: 88, w1: 2.063764946969233, w2: 0.9965391791947716, bias: -1.4367645554866506, loss: 0.5732628085121988\n",
      "Epochs: 89, w1: 2.0775835324219436, w2: 0.9987561991274752, bias: -1.4440361510429163, loss: 0.5727635114475975\n",
      "Epochs: 90, w1: 2.091381153769909, w2: 1.0009420516281817, bias: -1.4512747624088351, loss: 0.5722666210286019\n",
      "Epochs: 91, w1: 2.1051577265712504, w2: 1.003097311193995, bias: -1.4584808058468228, loss: 0.5717721145705856\n",
      "Epochs: 92, w1: 2.1189131690341, w2: 1.0052225415123381, bias: -1.4656546903507155, loss: 0.5712799699090172\n",
      "Epochs: 93, w1: 2.1326474019652952, w2: 1.0073182956731088, bias: -1.4727968177859148, loss: 0.570790165382002\n",
      "Epochs: 94, w1: 2.1463603487201146, w2: 1.009385116376438, bias: -1.479907583026555, loss: 0.5703026798134626\n",
      "Epochs: 95, w1: 2.1600519351530276, w2: 1.011423536136141, bias: -1.4869873740897745, loss: 0.5698174924969315\n",
      "Epochs: 96, w1: 2.173722089569431, w2: 1.0134340774789485, bias: -1.4940365722671682, loss: 0.5693345831799378\n",
      "Epochs: 97, w1: 2.1873707426783464, w2: 1.0154172531396048, bias: -1.5010555522534912, loss: 0.5688539320489615\n",
      "Epochs: 98, w1: 2.2009978275460513, w2: 1.0173735662519205, bias: -1.5080446822726843, loss: 0.5683755197149363\n",
      "Epochs: 99, w1: 2.214603279550627, w2: 1.0193035105358637, bias: -1.5150043242012858, loss: 0.5678993271992777\n",
      "Epochs: 100, w1: 2.228187036337397, w2: 1.021207570480777, bias: -1.5219348336892933, loss: 0.5674253359204205\n",
      "Epochs: 101, w1: 2.241749037775234, w2: 1.0230862215248024, bias: -1.5288365602785345, loss: 0.5669535276808444\n",
      "Epochs: 102, w1: 2.2552892259137214, w2: 1.0249399302305953, bias: -1.5357098475186086, loss: 0.5664838846545661\n",
      "Epochs: 103, w1: 2.2688075449411396, w2: 1.0267691544574107, bias: -1.54255503308045, loss: 0.5660163893750886\n",
      "Epochs: 104, w1: 2.2823039411432693, w2: 1.0285743435296395, bias: -1.5493724488675726, loss: 0.5655510247237827\n",
      "Epochs: 105, w1: 2.295778362862986, w2: 1.030355938401873, bias: -1.5561624211250462, loss: 0.5650877739186891\n",
      "Epochs: 106, w1: 2.3092307604606317, w2: 1.0321143718205703, bias: -1.5629252705462569, loss: 0.564626620503722\n",
      "Epochs: 107, w1: 2.3226610862751436, w2: 1.0338500684824057, bias: -1.5696613123774992, loss: 0.5641675483382641\n",
      "Epochs: 108, w1: 2.3360692945859296, w2: 1.035563445189367, bias: -1.5763708565204522, loss: 0.563710541587133\n",
      "Epochs: 109, w1: 2.3494553415754647, w2: 1.0372549110006768, bias: -1.5830542076325829, loss: 0.5632555847109085\n",
      "Epochs: 110, w1: 2.3628191852926017, w2: 1.0389248673816067, bias: -1.5897116652255252, loss: 0.5628026624566081\n",
      "Epochs: 111, w1: 2.376160785616578, w2: 1.040573708349253, bias: -1.5963435237614783, loss: 0.5623517598486931\n",
      "Epochs: 112, w1: 2.3894801042217, w2: 1.0422018206153387, bias: -1.6029500727476678, loss: 0.5619028621803996\n",
      "Epochs: 113, w1: 2.402777104542696, w2: 1.04380958372611, bias: -1.6095315968289132, loss: 0.5614559550053766\n",
      "Epochs: 114, w1: 2.416051751740722, w2: 1.0453973701993888, bias: -1.6160883758783422, loss: 0.5610110241296223\n",
      "Epochs: 115, w1: 2.429304012670004, w2: 1.0469655456588438, bias: -1.6226206850862908, loss: 0.5605680556037097\n",
      "Epochs: 116, w1: 2.442533855845106, w2: 1.0485144689655421, bias: -1.6291287950474327, loss: 0.5601270357152859\n",
      "Epochs: 117, w1: 2.455741251408813, w2: 1.0500444923468393, bias: -1.6356129718461718, loss: 0.559687950981839\n",
      "Epochs: 118, w1: 2.4689261711006103, w2: 1.051555961522667, bias: -1.642073477140338, loss: 0.5592507881437216\n",
      "Epochs: 119, w1: 2.4820885882257517, w2: 1.0530492158292744, bias: -1.6485105682432224, loss: 0.5588155341574205\n",
      "Epochs: 120, w1: 2.495228477624902, w2: 1.0545245883404786, bias: -1.6549244982039868, loss: 0.5583821761890648\n",
      "Epochs: 121, w1: 2.508345815644344, w2: 1.0559824059864795, bias: -1.661315515886484, loss: 0.557950701608164\n",
      "Epochs: 122, w1: 2.5214405801067366, w2: 1.0574229896702894, bias: -1.6676838660465214, loss: 0.5575210979815647\n",
      "Epochs: 123, w1: 2.5345127502824147, w2: 1.0588466543818316, bias: -1.6740297894076013, loss: 0.5570933530676219\n",
      "Epochs: 124, w1: 2.547562306861218, w2: 1.0602537093097564, bias: -1.680353522735171, loss: 0.5566674548105742\n",
      "Epochs: 125, w1: 2.560589231924838, w2: 1.0616444579510254, bias: -1.6866552989094146, loss: 0.5562433913351179\n",
      "Epochs: 126, w1: 2.573593508919676, w2: 1.0630191982183104, bias: -1.6929353469966169, loss: 0.5558211509411678\n",
      "Epochs: 127, w1: 2.5865751226301987, w2: 1.0643782225452556, bias: -1.6991938923191283, loss: 0.5554007220988053\n",
      "Epochs: 128, w1: 2.599534059152782, w2: 1.065721817989648, bias: -1.705431156523964, loss: 0.5549820934434008\n",
      "Epochs: 129, w1: 2.6124703058700334, w2: 1.0670502663345405, bias: -1.711647357650061, loss: 0.5545652537709059\n",
      "Epochs: 130, w1: 2.625383851425585, w2: 1.0683638441873728, bias: -1.7178427101942275, loss: 0.5541501920333112\n",
      "Epochs: 131, w1: 2.638274685699345, w2: 1.0696628230771315, bias: -1.7240174251758056, loss: 0.5537368973342596\n",
      "Epochs: 132, w1: 2.651142799783202, w2: 1.070947469549591, bias: -1.7301717102000793, loss: 0.5533253589248148\n",
      "Epochs: 133, w1: 2.663988185957171, w2: 1.0722180452606793, bias: -1.7363057695204513, loss: 0.5529155661993731\n",
      "Epochs: 134, w1: 2.6768108376659714, w2: 1.0734748070680022, bias: -1.742419804099415, loss: 0.5525075086917203\n",
      "Epochs: 135, w1: 2.6896107494960337, w2: 1.074718007120572, bias: -1.7485140116683473, loss: 0.5521011760712203\n",
      "Epochs: 136, w1: 2.7023879171529184, w2: 1.0759478929467723, bias: -1.7545885867861464, loss: 0.5516965581391399\n",
      "Epochs: 137, w1: 2.715142337439147, w2: 1.0771647075406026, bias: -1.760643720896737, loss: 0.5512936448250959\n",
      "Epochs: 138, w1: 2.7278740082324338, w2: 1.0783686894462317, bias: -1.7666796023854696, loss: 0.5508924261836268\n",
      "Epochs: 139, w1: 2.740582928464309, w2: 1.0795600728409025, bias: -1.7726964166344343, loss: 0.5504928923908811\n",
      "Epochs: 140, w1: 2.7532690980991283, w2: 1.0807390876162168, bias: -1.778694346076711, loss: 0.5500950337414183\n",
      "Epochs: 141, w1: 2.7659325181134626, w2: 1.0819059594578393, bias: -1.7846735702495806, loss: 0.549698840645121\n",
      "Epochs: 142, w1: 2.778573190475855, w2: 1.0830609099236488, bias: -1.790634265846715, loss: 0.54930430362421\n",
      "Epochs: 143, w1: 2.791191118126944, w2: 1.0842041565203735, bias: -1.7965766067693703, loss: 0.5489114133103623\n",
      "Epochs: 144, w1: 2.8037863049599463, w2: 1.085335912778739, bias: -1.8025007641766018, loss: 0.5485201604419263\n",
      "Epochs: 145, w1: 2.8163587558014824, w2: 1.0864563883271607, bias: -1.8084069065345196, loss: 0.5481305358612326\n",
      "Epochs: 146, w1: 2.828908476392755, w2: 1.087565788964012, bias: -1.8142951996646073, loss: 0.5477425305119937\n",
      "Epochs: 147, w1: 2.8414354733710563, w2: 1.088664316728495, bias: -1.8201658067911202, loss: 0.5473561354367932\n",
      "Epochs: 148, w1: 2.853939754251613, w2: 1.0897521699701465, bias: -1.8260188885875832, loss: 0.5469713417746573\n",
      "Epochs: 149, w1: 2.8664213274097525, w2: 1.0908295434170034, bias: -1.831854603222406, loss: 0.5465881407587113\n",
      "Epochs: 150, w1: 2.878880202063386, w2: 1.0918966282424585, bias: -1.8376731064036333, loss: 0.5462065237139113\n",
      "Epochs: 151, w1: 2.8913163882558086, w2: 1.0929536121308303, bias: -1.8434745514228492, loss: 0.5458264820548531\n",
      "Epochs: 152, w1: 2.9037298968388026, w2: 1.0940006793416772, bias: -1.849259089198249, loss: 0.5454480072836545\n",
      "Epochs: 153, w1: 2.9161207394560447, w2: 1.0950380107728777, bias: -1.8550268683168996, loss: 0.5450710909879073\n",
      "Epochs: 154, w1: 2.9284889285268063, w2: 1.0960657840225045, bias: -1.860778035076202, loss: 0.544695724838698\n",
      "Epochs: 155, w1: 2.940834477229946, w2: 1.0970841734495165, bias: -1.8665127335245728, loss: 0.5443219005886926\n",
      "Epochs: 156, w1: 2.9531573994881843, w2: 1.0980933502332917, bias: -1.8722311055013596, loss: 0.5439496100702871\n",
      "Epochs: 157, w1: 2.9654577099526622, w2: 1.0990934824320266, bias: -1.8779332906760071, loss: 0.5435788451938158\n",
      "Epochs: 158, w1: 2.9777354239877685, w2: 1.1000847350400225, bias: -1.8836194265864874, loss: 0.5432095979458211\n",
      "Epochs: 159, w1: 2.989990557656241, w2: 1.1010672700438837, bias: -1.8892896486770097, loss: 0.5428418603873787\n",
      "Epochs: 160, w1: 3.0022231277045304, w2: 1.1020412464776486, bias: -1.894944090335023, loss: 0.5424756246524773\n",
      "Epochs: 161, w1: 3.014433151548425, w2: 1.1030068204768737, bias: -1.9005828829275286, loss: 0.5421108829464518\n",
      "Epochs: 162, w1: 3.0266206472589268, w2: 1.1039641453316948, bias: -1.9062061558367112, loss: 0.5417476275444663\n",
      "Epochs: 163, w1: 3.0387856335483834, w2: 1.1049133715388832, bias: -1.9118140364949066, loss: 0.5413858507900479\n",
      "Epochs: 164, w1: 3.0509281297568616, w2: 1.105854646852918, bias: -1.9174066504189173, loss: 0.5410255450936652\n",
      "Epochs: 165, w1: 3.0630481558387626, w2: 1.1067881163360949, bias: -1.9229841212436882, loss: 0.5406667029313558\n",
      "Epochs: 166, w1: 3.075145732349677, w2: 1.1077139224076888, bias: -1.9285465707553557, loss: 0.5403093168433944\n",
      "Epochs: 167, w1: 3.0872208804334687, w2: 1.1086322048921928, bias: -1.9340941189236835, loss: 0.5399533794330066\n",
      "Epochs: 168, w1: 3.0992736218095907, w2: 1.1095431010666466, bias: -1.9396268839338946, loss: 0.5395988833651209\n",
      "Epochs: 169, w1: 3.111303978760623, w2: 1.1104467457070775, bias: -1.9451449822179139, loss: 0.5392458213651613\n",
      "Epochs: 170, w1: 3.123311974120033, w2: 1.111343271134069, bias: -1.950648528485032, loss: 0.5388941862178797\n",
      "Epochs: 171, w1: 3.1352976312601486, w2: 1.1122328072574743, bias: -1.9561376357520004, loss: 0.5385439707662217\n",
      "Epochs: 172, w1: 3.1472609740803494, w2: 1.1131154816202935, bias: -1.9616124153725711, loss: 0.5381951679102319\n",
      "Epochs: 173, w1: 3.159202026995462, w2: 1.1139914194417277, bias: -1.96707297706649, loss: 0.5378477706059898\n",
      "Epochs: 174, w1: 3.1711208149243633, w2: 1.1148607436594298, bias: -1.9725194289479553, loss: 0.5375017718645813\n",
      "Epochs: 175, w1: 3.1830173632787826, w2: 1.115723574970965, bias: -1.9779518775535507, loss: 0.5371571647511\n",
      "Epochs: 176, w1: 3.1948916979523054, w2: 1.1165800318745, bias: -1.9833704278696656, loss: 0.5368139423836822\n",
      "Epochs: 177, w1: 3.206743845309568, w2: 1.1174302307087305, bias: -1.9887751833594083, loss: 0.5364720979325689\n",
      "Epochs: 178, w1: 3.218573832175644, w2: 1.1182742856920673, bias: -1.9941662459890268, loss: 0.5361316246191975\n",
      "Epochs: 179, w1: 3.23038168582562, w2: 1.1191123089610941, bias: -1.9995437162538428, loss: 0.5357925157153212\n",
      "Epochs: 180, w1: 3.242167433974353, w2: 1.1199444106083087, bias: -2.0049076932037093, loss: 0.5354547645421551\n",
      "Epochs: 181, w1: 3.2539311047664135, w2: 1.120770698719164, bias: -2.010258274468004, loss: 0.5351183644695484\n",
      "Epochs: 182, w1: 3.2656727267661982, w2: 1.1215912794084228, bias: -2.015595556280162, loss: 0.5347833089151804\n",
      "Epochs: 183, w1: 3.2773923289482267, w2: 1.1224062568558382, bias: -2.020919633501761, loss: 0.5344495913437822\n",
      "Epochs: 184, w1: 3.289089940687604, w2: 1.1232157333411728, bias: -2.0262305996461647, loss: 0.5341172052663793\n",
      "Epochs: 185, w1: 3.3007655917506535, w2: 1.1240198092785707, bias: -2.0315285469017375, loss: 0.5337861442395591\n",
      "Epochs: 186, w1: 3.3124193122857153, w2: 1.1248185832502946, bias: -2.0368135661546316, loss: 0.533456401864758\n",
      "Epochs: 187, w1: 3.3240511328141085, w2: 1.1256121520398383, bias: -2.0420857470111606, loss: 0.533127971787571\n",
      "Epochs: 188, w1: 3.335661084221251, w2: 1.12640061066443, bias: -2.0473451778197655, loss: 0.5328008476970791\n",
      "Epochs: 189, w1: 3.34724919774794, w2: 1.1271840524069348, bias: -2.0525919456925794, loss: 0.5324750233251995\n",
      "Epochs: 190, w1: 3.358815504981784, w2: 1.1279625688471708, bias: -2.0578261365266015, loss: 0.5321504924460511\n",
      "Epochs: 191, w1: 3.370360037848787, w2: 1.128736249892648, bias: -2.0630478350244856, loss: 0.5318272488753398\n",
      "Epochs: 192, w1: 3.381882828605085, w2: 1.1295051838087424, bias: -2.06825712471495, loss: 0.5315052864697627\n",
      "Epochs: 193, w1: 3.393383909828824, w2: 1.1302694572483143, bias: -2.073454087972819, loss: 0.5311845991264259\n",
      "Epochs: 194, w1: 3.404863314412186, w2: 1.131029155280785, bias: -2.0786388060387004, loss: 0.5308651807822806\n",
      "Epochs: 195, w1: 3.416321075553554, w2: 1.1317843614206777, bias: -2.0838113590383047, loss: 0.5305470254135759\n",
      "Epochs: 196, w1: 3.4277572267498195, w2: 1.1325351576556373, bias: -2.088971826001417, loss: 0.5302301270353239\n",
      "Epochs: 197, w1: 3.439171801788822, w2: 1.133281624473934, bias: -2.0941202848805247, loss: 0.5299144797007829\n",
      "Epochs: 198, w1: 3.450564834741927, w2: 1.1340238408914671, bias: -2.099256812569109, loss: 0.5296000775009516\n",
      "Epochs: 199, w1: 3.4619363599567334, w2: 1.1347618844782714, bias: -2.104381484919604, loss: 0.5292869145640796\n",
      "Epochs: 200, w1: 3.473286412049912, w2: 1.1354958313845407, bias: -2.109494376761035, loss: 0.5289749850551891\n",
      "Epochs: 201, w1: 3.4846150259001707, w2: 1.1362257563661764, bias: -2.1145955619163366, loss: 0.5286642831756109\n",
      "Epochs: 202, w1: 3.495922236641346, w2: 1.1369517328098686, bias: -2.119685113219359, loss: 0.5283548031625321\n",
      "Epochs: 203, w1: 3.507208079655616, w2: 1.1376738327577196, bias: -2.1247631025315683, loss: 0.5280465392885548\n",
      "Epochs: 204, w1: 3.5184725905668377, w2: 1.1383921269314201, bias: -2.1298296007584465, loss: 0.5277394858612695\n",
      "Epochs: 205, w1: 3.5297158052339976, w2: 1.1391066847559828, bias: -2.1348846778655965, loss: 0.5274336372228342\n",
      "Epochs: 206, w1: 3.5409377597447858, w2: 1.1398175743830457, bias: -2.1399284028945575, loss: 0.5271289877495702\n",
      "Epochs: 207, w1: 3.5521384904092805, w2: 1.1405248627137503, bias: -2.144960843978337, loss: 0.5268255318515647\n",
      "Epochs: 208, w1: 3.563318033753747, w2: 1.141228615421205, bias: -2.149982068356665, loss: 0.5265232639722831\n",
      "Epochs: 209, w1: 3.5744764265145483, w2: 1.1419288969725385, bias: -2.154992142390971, loss: 0.5262221785881945\n",
      "Epochs: 210, w1: 3.5856137056321638, w2: 1.1426257706505552, bias: -2.159991131579098, loss: 0.525922270208402\n",
      "Epochs: 211, w1: 3.5967299082453144, w2: 1.1433192985749945, bias: -2.164979100569749, loss: 0.5256235333742857\n",
      "Epochs: 212, w1: 3.6078250716851965, w2: 1.1440095417234077, bias: -2.1699561131766774, loss: 0.5253259626591525\n",
      "Epochs: 213, w1: 3.618899233469816, w2: 1.1446965599516543, bias: -2.1749222323926225, loss: 0.5250295526678953\n",
      "Epochs: 214, w1: 3.6299524312984253, w2: 1.1453804120140278, bias: -2.179877520402996, loss: 0.5247342980366593\n",
      "Epochs: 215, w1: 3.6409847030460623, w2: 1.1460611555830171, bias: -2.1848220385993264, loss: 0.5244401934325184\n",
      "Epochs: 216, w1: 3.6519960867581847, w2: 1.1467388472687101, bias: -2.18975584759246, loss: 0.5241472335531561\n",
      "Epochs: 217, w1: 3.6629866206454023, w2: 1.1474135426378462, bias: -2.1946790072255293, loss: 0.5238554131265564\n",
      "Epochs: 218, w1: 3.6739563430783067, w2: 1.148085296232525, bias: -2.199591576586689, loss: 0.5235647269107009\n",
      "Epochs: 219, w1: 3.68490529258239, w2: 1.1487541615885768, bias: -2.2044936140216267, loss: 0.5232751696932728\n",
      "Epochs: 220, w1: 3.6958335078330595, w2: 1.149420191253601, bias: -2.2093851771458497, loss: 0.5229867362913669\n",
      "Epochs: 221, w1: 3.7067410276507413, w2: 1.1500834368046797, bias: -2.2142663228567536, loss: 0.5226994215512089\n",
      "Epochs: 222, w1: 3.7176278909960705, w2: 1.1507439488657707, bias: -2.2191371073454764, loss: 0.5224132203478749\n",
      "Epochs: 223, w1: 3.7284941369651725, w2: 1.151401777124788, bias: -2.2239975861085437, loss: 0.5221281275850257\n",
      "Epochs: 224, w1: 3.739339804785028, w2: 1.1520569703503742, bias: -2.2288478139593044, loss: 0.5218441381946389\n",
      "Epochs: 225, w1: 3.750164933808922, w2: 1.1527095764083704, bias: -2.2336878450391664, loss: 0.5215612471367502\n",
      "Epochs: 226, w1: 3.760969563511976, w2: 1.15335964227799, bias: -2.238517732828632, loss: 0.5212794493992013\n",
      "Epochs: 227, w1: 3.7717537334867637, w2: 1.1540072140677016, bias: -2.2433375301581373, loss: 0.5209987399973909\n",
      "Epochs: 228, w1: 3.7825174834390034, w2: 1.1546523370308261, bias: -2.2481472892187013, loss: 0.5207191139740306\n",
      "Epochs: 229, w1: 3.7932608531833316, w2: 1.155295055580853, bias: -2.2529470615723852, loss: 0.5204405663989086\n",
      "Epochs: 230, w1: 3.8039838826391534, w2: 1.155935413306482, bias: -2.257736898162568, loss: 0.5201630923686552\n",
      "Epochs: 231, w1: 3.8146866118265694, w2: 1.1565734529863947, bias: -2.2625168493240393, loss: 0.5198866870065145\n",
      "Epochs: 232, w1: 3.8253690808623757, w2: 1.15720921660376, bias: -2.267286964792916, loss: 0.5196113454621201\n",
      "Epochs: 233, w1: 3.8360313299561404, w2: 1.15784274536048, bias: -2.2720472937163825, loss: 0.5193370629112751\n",
      "Epochs: 234, w1: 3.846673399406349, w2: 1.1584740796911814, bias: -2.276797884662258, loss: 0.519063834555737\n",
      "Epochs: 235, w1: 3.857295329596624, w2: 1.1591032592769532, bias: -2.2815387856283995, loss: 0.5187916556230058\n",
      "Epochs: 236, w1: 3.8678971609920123, w2: 1.159730323058841, bias: -2.2862700440519346, loss: 0.5185205213661166\n",
      "Epochs: 237, w1: 3.878478934135343, w2: 1.160355309251098, bias: -2.290991706818335, loss: 0.5182504270634359\n",
      "Epochs: 238, w1: 3.8890406896436507, w2: 1.1609782553541994, bias: -2.295703820270328, loss: 0.5179813680184613\n",
      "Epochs: 239, w1: 3.8995824682046663, w2: 1.161599198167623, bias: -2.300406430216655, loss: 0.5177133395596257\n",
      "Epochs: 240, w1: 3.910104310573374, w2: 1.1622181738024024, bias: -2.305099581940671, loss: 0.5174463370401038\n",
      "Epochs: 241, w1: 3.9206062575686307, w2: 1.1628352176934542, bias: -2.309783320208799, loss: 0.5171803558376227\n",
      "Epochs: 242, w1: 3.931088350069849, w2: 1.1634503646116856, bias: -2.314457689278831, loss: 0.5169153913542757\n",
      "Epochs: 243, w1: 3.9415506290137436, w2: 1.1640636486758857, bias: -2.3191227329080877, loss: 0.5166514390163396\n",
      "Epochs: 244, w1: 3.951993135391137, w2: 1.1646751033644036, bias: -2.3237784943614317, loss: 0.516388494274094\n",
      "Epochs: 245, w1: 3.962415910243825, w2: 1.1652847615266189, bias: -2.328425016419143, loss: 0.5161265526016446\n",
      "Epochs: 246, w1: 3.9728189946615022, w2: 1.1658926553942064, bias: -2.333062341384656, loss: 0.5158656094967493\n",
      "Epochs: 247, w1: 3.9832024297787463, w2: 1.1664988165922, bias: -2.3376905110921604, loss: 0.5156056604806462\n",
      "Epochs: 248, w1: 3.993566256772056, w2: 1.1671032761498596, bias: -2.34230956691407, loss: 0.5153467010978856\n",
      "Epochs: 249, w1: 4.003910516856949, w2: 1.1677060645113444, bias: -2.3469195497683626, loss: 0.5150887269161646\n",
      "Epochs: 250, w1: 4.014235251285109, w2: 1.168307211546194, bias: -2.3515205001257873, loss: 0.5148317335261617\n",
      "Epochs: 251, w1: 4.024540501341598, w2: 1.1689067465596255, bias: -2.356112458016952, loss: 0.5145757165413783\n",
      "Epochs: 252, w1: 4.034826308342105, w2: 1.1695046983026438, bias: -2.360695463039283, loss: 0.5143206715979786\n",
      "Epochs: 253, w1: 4.045092713630266, w2: 1.1701010949819752, bias: -2.3652695543638655, loss: 0.5140665943546336\n",
      "Epochs: 254, w1: 4.05533975857502, w2: 1.1706959642698216, bias: -2.369834770742164, loss: 0.5138134804923685\n",
      "Epochs: 255, w1: 4.065567484568021, w2: 1.171289333313442, bias: -2.3743911505126256, loss: 0.5135613257144092\n",
      "Epochs: 256, w1: 4.075775933021104, w2: 1.1718812287445628, bias: -2.378938731607171, loss: 0.5133101257460342\n",
      "Epochs: 257, w1: 4.085965145363794, w2: 1.172471676688622, bias: -2.38347755155757, loss: 0.5130598763344266\n",
      "Epochs: 258, w1: 4.096135163040863, w2: 1.1730607027738473, bias: -2.3880076475017056, loss: 0.5128105732485289\n",
      "Epochs: 259, w1: 4.106286027509939, w2: 1.1736483321401736, bias: -2.392529056189734, loss: 0.5125622122788993\n",
      "Epochs: 260, w1: 4.116417780239157, w2: 1.174234589448002, bias: -2.397041813990132, loss: 0.5123147892375705\n",
      "Epochs: 261, w1: 4.126530462704857, w2: 1.1748194988868026, bias: -2.4015459568956445, loss: 0.5120682999579097\n",
      "Epochs: 262, w1: 4.136624116389329, w2: 1.1754030841835652, bias: -2.406041520529126, loss: 0.511822740294481\n",
      "Epochs: 263, w1: 4.1466987827785955, w2: 1.1759853686110986, bias: -2.410528540149282, loss: 0.5115781061229098\n",
      "Epochs: 264, w1: 4.156754503360246, w2: 1.1765663749961839, bias: -2.4150070506563113, loss: 0.5113343933397473\n",
      "Epochs: 265, w1: 4.166791319621309, w2: 1.1771461257275817, bias: -2.41947708659745, loss: 0.5110915978623387\n",
      "Epochs: 266, w1: 4.176809273046164, w2: 1.177724642763898, bias: -2.423938682172422, loss: 0.5108497156286923\n",
      "Epochs: 267, w1: 4.186808405114501, w2: 1.1783019476413108, bias: -2.428391871238791, loss: 0.5106087425973487\n",
      "Epochs: 268, w1: 4.1967887572993146, w2: 1.1788780614811576, bias: -2.4328366873172254, loss: 0.5103686747472546\n",
      "Epochs: 269, w1: 4.20675037106494, w2: 1.179453004997391, bias: -2.437273163596669, loss: 0.5101295080776348\n",
      "Epochs: 270, w1: 4.21669328786513, w2: 1.1800267985039, bias: -2.441701332939423, loss: 0.5098912386078687\n",
      "Epochs: 271, w1: 4.226617549141167, w2: 1.180599461921702, bias: -2.446121227886142, loss: 0.5096538623773651\n",
      "Epochs: 272, w1: 4.2365231963200145, w2: 1.1811710147860077, bias: -2.450532880660744, loss: 0.5094173754454413\n",
      "Epochs: 273, w1: 4.246410270812505, w2: 1.1817414762531606, bias: -2.4549363231752324, loss: 0.5091817738912017\n",
      "Epochs: 274, w1: 4.256278814011567, w2: 1.182310865107453, bias: -2.4593315870344403, loss: 0.5089470538134184\n",
      "Epochs: 275, w1: 4.266128867290483, w2: 1.1828791997678212, bias: -2.4637187035406907, loss: 0.5087132113304128\n",
      "Epochs: 276, w1: 4.27596047200119, w2: 1.1834464982944233, bias: -2.468097703698376, loss: 0.508480242579939\n",
      "Epochs: 277, w1: 4.285773669472604, w2: 1.1840127783950987, bias: -2.4724686182184614, loss: 0.5082481437190673\n",
      "Epochs: 278, w1: 4.295568501008992, w2: 1.1845780574317144, bias: -2.476831477522908, loss: 0.508016910924071\n",
      "Epochs: 279, w1: 4.305345007888363, w2: 1.1851423524263986, bias: -2.481186311749024, loss: 0.5077865403903112\n",
      "Epochs: 280, w1: 4.315103231360904, w2: 1.185705680067664, bias: -2.485533150753738, loss: 0.5075570283321255\n",
      "Epochs: 281, w1: 4.324843212647444, w2: 1.1862680567164217, bias: -2.4898720241178007, loss: 0.507328370982718\n",
      "Epochs: 282, w1: 4.334564992937946, w2: 1.1868294984118908, bias: -2.494202961149915, loss: 0.5071005645940464\n",
      "Epochs: 283, w1: 4.344268613390037, w2: 1.1873900208774009, bias: -2.498525990890795, loss: 0.5068736054367157\n",
      "Epochs: 284, w1: 4.353954115127562, w2: 1.1879496395260938, bias: -2.5028411421171572, loss: 0.5066474897998682\n",
      "Epochs: 285, w1: 4.363621539239175, w2: 1.1885083694665235, bias: -2.5071484433456415, loss: 0.5064222139910787\n",
      "Epochs: 286, w1: 4.373270926776955, w2: 1.1890662255081574, bias: -2.5114479228366666, loss: 0.5061977743362458\n",
      "Epochs: 287, w1: 4.382902318755052, w2: 1.1896232221667795, bias: -2.5157396085982193, loss: 0.5059741671794896\n",
      "Epochs: 288, w1: 4.392515756148361, w2: 1.190179373669799, bias: -2.52002352838958, loss: 0.5057513888830456\n",
      "Epochs: 289, w1: 4.402111279891229, w2: 1.1907346939614645, bias: -2.5242997097249855, loss: 0.5055294358271627\n",
      "Epochs: 290, w1: 4.411688930876182, w2: 1.1912891967079864, bias: -2.528568179877226, loss: 0.5053083044100007\n",
      "Epochs: 291, w1: 4.421248749952687, w2: 1.191842895302568, bias: -2.532828965881186, loss: 0.5050879910475289\n",
      "Epochs: 292, w1: 4.430790777925933, w2: 1.1923958028703479, bias: -2.537082094537322, loss: 0.5048684921734252\n",
      "Epochs: 293, w1: 4.4403150555556445, w2: 1.192947932273256, bias: -2.5413275924150813, loss: 0.5046498042389774\n",
      "Epochs: 294, w1: 4.449821623554921, w2: 1.193499296114782, bias: -2.545565485856265, loss: 0.5044319237129837\n",
      "Epochs: 295, w1: 4.459310522589094, w2: 1.194049906744661, bias: -2.5497958009783313, loss: 0.5042148470816549\n",
      "Epochs: 296, w1: 4.468781793274621, w2: 1.1945997762634764, bias: -2.554018563677645, loss: 0.5039985708485176\n",
      "Epochs: 297, w1: 4.478235476177992, w2: 1.1951489165271791, bias: -2.558233799632672, loss: 0.5037830915343176\n",
      "Epochs: 298, w1: 4.487671611814668, w2: 1.1956973391515304, bias: -2.562441534307118, loss: 0.5035684056769236\n",
      "Epochs: 299, w1: 4.497090240648043, w2: 1.1962450555164639, bias: -2.5666417929530154, loss: 0.5033545098312339\n",
      "Epochs: 300, w1: 4.506491403088423, w2: 1.1967920767703706, bias: -2.570834600613761, loss: 0.5031414005690805\n",
      "Epochs: 301, w1: 4.515875139492035, w2: 1.19733841383431, bias: -2.5750199821270967, loss: 0.5029290744791376\n",
      "Epochs: 302, w1: 4.525241490160057, w2: 1.197884077406144, bias: -2.579197962128044, loss: 0.502717528166827\n",
      "Epochs: 303, w1: 4.534590495337663, w2: 1.1984290779646012, bias: -2.58336856505179, loss: 0.5025067582542279\n",
      "Epochs: 304, w1: 4.543922195213102, w2: 1.1989734257732656, bias: -2.58753181513652, loss: 0.5022967613799848\n",
      "Epochs: 305, w1: 4.553236629916787, w2: 1.1995171308844985, bias: -2.5916877364262088, loss: 0.5020875341992164\n",
      "Epochs: 306, w1: 4.562533839520413, w2: 1.2000602031432888, bias: -2.59583635277336, loss: 0.5018790733834275\n",
      "Epochs: 307, w1: 4.571813864036091, w2: 1.2006026521910356, bias: -2.5999776878417036, loss: 0.5016713756204179\n",
      "Epochs: 308, w1: 4.581076743415503, w2: 1.2011444874692652, bias: -2.604111765108844, loss: 0.5014644376141937\n",
      "Epochs: 309, w1: 4.590322517549077, w2: 1.201685718223281, bias: -2.6082386078688673, loss: 0.5012582560848815\n",
      "Epochs: 310, w1: 4.599551226265186, w2: 1.20222635350575, bias: -2.6123582392349034, loss: 0.5010528277686396\n",
      "Epochs: 311, w1: 4.608762909329358, w2: 1.2027664021802253, bias: -2.616470682141646, loss: 0.50084814941757\n",
      "Epochs: 312, w1: 4.617957606443511, w2: 1.2033058729246071, bias: -2.6205759593478293, loss: 0.5006442177996352\n",
      "Epochs: 313, w1: 4.627135357245205, w2: 1.2038447742345417, bias: -2.624674093438665, loss: 0.5004410296985701\n",
      "Epochs: 314, w1: 4.636296201306911, w2: 1.2043831144267616, bias: -2.628765106828237, loss: 0.5002385819137986\n",
      "Epochs: 315, w1: 4.645440178135302, w2: 1.2049209016423648, bias: -2.6328490217618583, loss: 0.5000368712603491\n",
      "Epochs: 316, w1: 4.654567327170553, w2: 1.2054581438500387, bias: -2.6369258603183874, loss: 0.49983589456876937\n",
      "Epochs: 317, w1: 4.663677687785669, w2: 1.2059948488492254, bias: -2.640995644412505, loss: 0.4996356486850454\n",
      "Epochs: 318, w1: 4.672771299285824, w2: 1.206531024273231, bias: -2.6450583957969553, loss: 0.4994361304705171\n",
      "Epochs: 319, w1: 4.681848200907712, w2: 1.2070666775922807, bias: -2.6491141360647497, loss: 0.4992373368017969\n",
      "Epochs: 320, w1: 4.690908431818929, w2: 1.20760181611652, bias: -2.653162886651332, loss: 0.49903926457068815\n",
      "Epochs: 321, w1: 4.6999520311173555, w2: 1.2081364469989628, bias: -2.6572046688367097, loss: 0.498841910684104\n",
      "Epochs: 322, w1: 4.708979037830563, w2: 1.2086705772383866, bias: -2.6612395037475496, loss: 0.49864527206398646\n",
      "Epochs: 323, w1: 4.717989490915235, w2: 1.2092042136821777, bias: -2.665267412359239, loss: 0.49844934564722787\n",
      "Epochs: 324, w1: 4.726983429256603, w2: 1.209737363029126, bias: -2.66928841549791, loss: 0.49825412838558913\n",
      "Epochs: 325, w1: 4.735960891667896, w2: 1.2102700318321695, bias: -2.673302533842438, loss: 0.49805961724562237\n",
      "Epochs: 326, w1: 4.744921916889808, w2: 1.2108022265010918, bias: -2.6773097879263954, loss: 0.49786580920859264\n",
      "Epochs: 327, w1: 4.753866543589975, w2: 1.2113339533051704, bias: -2.681310198139986, loss: 0.4976727012703988\n",
      "Epochs: 328, w1: 4.762794810362472, w2: 1.2118652183757792, bias: -2.6853037847319383, loss: 0.49748029044149633\n",
      "Epochs: 329, w1: 4.771706755727319, w2: 1.2123960277089456, bias: -2.689290567811371, loss: 0.49728857374682095\n",
      "Epochs: 330, w1: 4.780602418130005, w2: 1.2129263871678604, bias: -2.6932705673496287, loss: 0.4970975482257117\n",
      "Epochs: 331, w1: 4.789481835941023, w2: 1.2134563024853455, bias: -2.6972438031820856, loss: 0.4969072109318348\n",
      "Epochs: 332, w1: 4.798345047455419, w2: 1.213985779266277, bias: -2.701210295009922, loss: 0.4967175589331077\n",
      "Epochs: 333, w1: 4.8071920908923484, w2: 1.2145148229899652, bias: -2.7051700624018684, loss: 0.4965285893116246\n",
      "Epochs: 334, w1: 4.816023004394659, w2: 1.2150434390124931, bias: -2.709123124795925, loss: 0.49634029916358174\n",
      "Epochs: 335, w1: 4.824837826028474, w2: 1.2155716325690142, bias: -2.7130695015010495, loss: 0.49615268559920234\n",
      "Epochs: 336, w1: 4.8336365937827885, w2: 1.2160994087760075, bias: -2.7170092116988203, loss: 0.4959657457426635\n",
      "Epochs: 337, w1: 4.842419345569087, w2: 1.2166267726334954, bias: -2.7209422744450706, loss: 0.495779476732023\n",
      "Epochs: 338, w1: 4.85118611922096, w2: 1.2171537290272203, bias: -2.7248687086714964, loss: 0.4955938757191458\n",
      "Epochs: 339, w1: 4.859936952493747, w2: 1.2176802827307838, bias: -2.72878853318724, loss: 0.49540893986963164\n",
      "Epochs: 340, w1: 4.868671883064175, w2: 1.2182064384077473, bias: -2.7327017666804436, loss: 0.49522466636274376\n",
      "Epochs: 341, w1: 4.877390948530021, w2: 1.2187322006136971, bias: -2.7366084277197844, loss: 0.4950410523913357\n",
      "Epochs: 342, w1: 4.88609418640978, w2: 1.21925757379827, bias: -2.740508534755977, loss: 0.4948580951617819\n",
      "Epochs: 343, w1: 4.894781634142346, w2: 1.2197825623071468, bias: -2.7444021061232573, loss: 0.4946757918939055\n",
      "Epochs: 344, w1: 4.903453329086699, w2: 1.220307170384007, bias: -2.748289160040841, loss: 0.4944941398209087\n",
      "Epochs: 345, w1: 4.912109308521608, w2: 1.2208314021724511, bias: -2.7521697146143564, loss: 0.4943131361893023\n",
      "Epochs: 346, w1: 4.920749609645344, w2: 1.221355261717889, bias: -2.7560437878372577, loss: 0.4941327782588365\n",
      "Epochs: 347, w1: 4.929374269575397, w2: 1.2218787529693937, bias: -2.759911397592211, loss: 0.49395306330243155\n",
      "Epochs: 348, w1: 4.937983325348211, w2: 1.2224018797815221, bias: -2.763772561652463, loss: 0.49377398860610894\n",
      "Epochs: 349, w1: 4.946576813918922, w2: 1.2229246459161056, bias: -2.767627297683184, loss: 0.493595551468923\n",
      "Epochs: 350, w1: 4.955154772161112, w2: 1.2234470550440064, bias: -2.7714756232427904, loss: 0.4934177492028928\n",
      "Epochs: 351, w1: 4.963717236866566, w2: 1.2239691107468451, bias: -2.775317555784247, loss: 0.4932405791329347\n",
      "Epochs: 352, w1: 4.972264244745042, w2: 1.2244908165186958, bias: -2.7791531126563465, loss: 0.49306403859679515\n",
      "Epochs: 353, w1: 4.980795832424048, w2: 1.225012175767752, bias: -2.782982311104971, loss: 0.49288812494498374\n",
      "Epochs: 354, w1: 4.9893120364486325, w2: 1.2255331918179624, bias: -2.786805168274332, loss: 0.4927128355407067\n",
      "Epochs: 355, w1: 4.997812893281176, w2: 1.2260538679106399, bias: -2.7906217012081886, loss: 0.4925381677598004\n",
      "Epochs: 356, w1: 5.006298439301198, w2: 1.2265742072060384, bias: -2.7944319268510505, loss: 0.4923641189906666\n",
      "Epochs: 357, w1: 5.01476871080517, w2: 1.2270942127849047, bias: -2.7982358620493586, loss: 0.49219068663420595\n",
      "Epochs: 358, w1: 5.0232237440063345, w2: 1.2276138876500018, bias: -2.8020335235526486, loss: 0.49201786810375375\n",
      "Epochs: 359, w1: 5.031663575034535, w2: 1.2281332347276048, bias: -2.8058249280146947, loss: 0.49184566082501513\n",
      "Epochs: 360, w1: 5.040088239936053, w2: 1.2286522568689708, bias: -2.8096100919946365, loss: 0.49167406223600046\n",
      "Epochs: 361, w1: 5.0484977746734545, w2: 1.2291709568517826, bias: -2.813389031958087, loss: 0.49150306978696195\n",
      "Epochs: 362, w1: 5.05689221512544, w2: 1.2296893373815663, bias: -2.8171617642782247, loss: 0.49133268094032956\n",
      "Epochs: 363, w1: 5.065271597086705, w2: 1.2302074010930852, bias: -2.820928305236865, loss: 0.4911628931706478\n",
      "Epochs: 364, w1: 5.073635956267808, w2: 1.2307251505517067, bias: -2.82468867102552, loss: 0.4909937039645134\n",
      "Epochs: 365, w1: 5.081985328295048, w2: 1.231242588254747, bias: -2.8284428777464368, loss: 0.49082511082051244\n",
      "Epochs: 366, w1: 5.090319748710338, w2: 1.2317597166327907, bias: -2.8321909414136215, loss: 0.4906571112491576\n",
      "Epochs: 367, w1: 5.098639252971103, w2: 1.2322765380509872, bias: -2.8359328779538475, loss: 0.4904897027728276\n",
      "Epochs: 368, w1: 5.10694387645017, w2: 1.232793054810324, bias: -2.8396687032076473, loss: 0.49032288292570403\n",
      "Epochs: 369, w1: 5.115233654435671, w2: 1.233309269148878, bias: -2.843398432930288, loss: 0.49015664925371216\n",
      "Epochs: 370, w1: 5.123508622130954, w2: 1.2338251832430434, bias: -2.847122082792735, loss: 0.48999099931445794\n",
      "Epochs: 371, w1: 5.131768814654496, w2: 1.2343407992087387, bias: -2.850839668382595, loss: 0.4898259306771697\n",
      "Epochs: 372, w1: 5.140014267039825, w2: 1.2348561191025922, bias: -2.85455120520505, loss: 0.4896614409226357\n",
      "Epochs: 373, w1: 5.148245014235448, w2: 1.235371144923105, bias: -2.858256708683773, loss: 0.48949752764314614\n",
      "Epochs: 374, w1: 5.156461091104786, w2: 1.2358858786117959, bias: -2.861956194161831, loss: 0.4893341884424329\n",
      "Epochs: 375, w1: 5.164662532426113, w2: 1.236400322054323, bias: -2.865649676902573, loss: 0.4891714209356101\n",
      "Epochs: 376, w1: 5.172849372892501, w2: 1.2369144770815872, bias: -2.869337172090507, loss: 0.4890092227491159\n",
      "Epochs: 377, w1: 5.181021647111774, w2: 1.2374283454708155, bias: -2.8730186948321594, loss: 0.4888475915206531\n",
      "Epochs: 378, w1: 5.189179389606462, w2: 1.237941928946625, bias: -2.876694260156924, loss: 0.4886865248991315\n",
      "Epochs: 379, w1: 5.197322634813765, w2: 1.2384552291820676, bias: -2.8803638830178966, loss: 0.48852602054460975\n",
      "Epochs: 380, w1: 5.205451417085522, w2: 1.2389682477996569, bias: -2.884027578292698, loss: 0.48836607612823796\n",
      "Epochs: 381, w1: 5.2135657706881835, w2: 1.2394809863723752, bias: -2.8876853607842823, loss: 0.48820668933219996\n",
      "Epochs: 382, w1: 5.221665729802791, w2: 1.2399934464246647, bias: -2.891337245221736, loss: 0.4880478578496568\n",
      "Epochs: 383, w1: 5.22975132852496, w2: 1.240505629433399, bias: -2.8949832462610603, loss: 0.4878895793846899\n",
      "Epochs: 384, w1: 5.23782260086487, w2: 1.2410175368288379, bias: -2.898623378485947, loss: 0.4877318516522442\n",
      "Epochs: 385, w1: 5.245879580747255, w2: 1.2415291699955657, bias: -2.9022576564085383, loss: 0.48757467237807256\n",
      "Epochs: 386, w1: 5.253922302011407, w2: 1.2420405302734125, bias: -2.9058860944701745, loss: 0.4874180392986806\n",
      "Epochs: 387, w1: 5.261950798411176, w2: 1.2425516189583579, bias: -2.909508707042136, loss: 0.4872619501612698\n",
      "Epochs: 388, w1: 5.269965103614977, w2: 1.2430624373034196, bias: -2.9131255084263676, loss: 0.4871064027236825\n",
      "Epochs: 389, w1: 5.277965251205807, w2: 1.2435729865195264, bias: -2.9167365128561946, loss: 0.48695139475434934\n",
      "Epochs: 390, w1: 5.285951274681257, w2: 1.2440832677763745, bias: -2.920341734497029, loss: 0.48679692403223124\n",
      "Epochs: 391, w1: 5.2939232074535365, w2: 1.244593282203269, bias: -2.9239411874470638, loss: 0.4866429883467677\n",
      "Epochs: 392, w1: 5.301881082849497, w2: 1.2451030308899507, bias: -2.9275348857379555, loss: 0.4864895854978213\n",
      "Epochs: 393, w1: 5.309824934110663, w2: 1.2456125148874067, bias: -2.9311228433355003, loss: 0.4863367132956247\n",
      "Epochs: 394, w1: 5.3177547943932675, w2: 1.246121735208668, bias: -2.9347050741402954, loss: 0.48618436956072736\n",
      "Epochs: 395, w1: 5.3256706967682845, w2: 1.246630692829592, bias: -2.9382815919883933, loss: 0.4860325521239421\n",
      "Epochs: 396, w1: 5.333572674221478, w2: 1.2471393886896311, bias: -2.9418524106519475, loss: 0.4858812588262914\n",
      "Epochs: 397, w1: 5.341460759653442, w2: 1.2476478236925868, bias: -2.945417543839844, loss: 0.485730487518957\n",
      "Epochs: 398, w1: 5.349334985879652, w2: 1.2481559987073516, bias: -2.9489770051983286, loss: 0.48558023606322503\n",
      "Epochs: 399, w1: 5.357195385630521, w2: 1.2486639145686365, bias: -2.9525308083116197, loss: 0.48543050233043594\n",
      "Epochs: 400, w1: 5.365041991551451, w2: 1.2491715720776855, bias: -2.956078966702517, loss: 0.48528128420193234\n",
      "Epochs: 401, w1: 5.3728748362028975, w2: 1.2496789720029773, bias: -2.9596214938329983, loss: 0.48513257956900624\n",
      "Epochs: 402, w1: 5.380693952060431, w2: 1.250186115080915, bias: -2.963158403104808, loss: 0.4849843863328498\n",
      "Epochs: 403, w1: 5.388499371514807, w2: 1.2506930020165026, bias: -2.9666897078600365, loss: 0.4848367024045037\n",
      "Epochs: 404, w1: 5.3962911268720335, w2: 1.2511996334840083, bias: -2.970215421381692, loss: 0.48468952570480556\n",
      "Epochs: 405, w1: 5.404069250353447, w2: 1.2517060101276187, bias: -2.9737355568942627, loss: 0.48454285416434073\n",
      "Epochs: 406, w1: 5.41183377409579, w2: 1.2522121325620785, bias: -2.977250127564274, loss: 0.48439668572339173\n",
      "Epochs: 407, w1: 5.419584730151289, w2: 1.2527180013733195, bias: -2.9807591465008314, loss: 0.48425101833188894\n",
      "Epochs: 408, w1: 5.427322150487741, w2: 1.2532236171190783, bias: -2.9842626267561623, loss: 0.48410584994936007\n",
      "Epochs: 409, w1: 5.435046066988596, w2: 1.2537289803295033, bias: -2.9877605813261443, loss: 0.48396117854488163\n",
      "Epochs: 410, w1: 5.442756511453049, w2: 1.2542340915077497, bias: -2.9912530231508305, loss: 0.48381700209702977\n",
      "Epochs: 411, w1: 5.4504535155961324, w2: 1.254738951130564, bias: -2.994739965114963, loss: 0.4836733185938313\n",
      "Epochs: 412, w1: 5.45813711104881, w2: 1.2552435596488587, bias: -2.998221420048482, loss: 0.483530126032715\n",
      "Epochs: 413, w1: 5.465807329358074, w2: 1.2557479174882753, bias: -3.0016974007270254, loss: 0.48338742242046406\n",
      "Epochs: 414, w1: 5.4734642019870465, w2: 1.256252025049738, bias: -3.005167919872424, loss: 0.48324520577316776\n",
      "Epochs: 415, w1: 5.4811077603150835, w2: 1.2567558827099967, bias: -3.008632990153187, loss: 0.4831034741161734\n",
      "Epochs: 416, w1: 5.488738035637878, w2: 1.257259490822161, bias: -3.0120926241849797, loss: 0.48296222548403894\n",
      "Epochs: 417, w1: 5.49635505916757, w2: 1.2577628497162232, bias: -3.0155468345310985, loss: 0.48282145792048625\n",
      "Epochs: 418, w1: 5.5039588620328574, w2: 1.2582659596995731, bias: -3.0189956337029353, loss: 0.48268116947835354\n",
      "Epochs: 419, w1: 5.511549475279107, w2: 1.258768821057502, bias: -3.0224390341604375, loss: 0.4825413582195491\n",
      "Epochs: 420, w1: 5.519126929868473, w2: 1.259271434053699, bias: -3.0258770483125588, loss: 0.48240202221500417\n",
      "Epochs: 421, w1: 5.526691256680012, w2: 1.259773798930737, bias: -3.0293096885177078, loss: 0.4822631595446278\n",
      "Epochs: 422, w1: 5.534242486509804, w2: 1.2602759159105503, bias: -3.032736967084186, loss: 0.48212476829725953\n",
      "Epochs: 423, w1: 5.5417806500710745, w2: 1.260777785194904, bias: -3.0361588962706225, loss: 0.4819868465706248\n",
      "Epochs: 424, w1: 5.549305777994319, w2: 1.2612794069658533, bias: -3.0395754882864003, loss: 0.48184939247128855\n",
      "Epochs: 425, w1: 5.556817900827429, w2: 1.2617807813861959, bias: -3.04298675529208, loss: 0.48171240411461125\n",
      "Epochs: 426, w1: 5.5643170490358225, w2: 1.2622819085999155, bias: -3.0463927093998127, loss: 0.4815758796247019\n",
      "Epochs: 427, w1: 5.57180325300257, w2: 1.2627827887326168, bias: -3.049793362673752, loss: 0.4814398171343753\n",
      "Epochs: 428, w1: 5.579276543028532, w2: 1.2632834218919533, bias: -3.0531887271304576, loss: 0.48130421478510627\n",
      "Epochs: 429, w1: 5.586736949332488, w2: 1.2637838081680461, bias: -3.056578814739293, loss: 0.48116907072698556\n",
      "Epochs: 430, w1: 5.594184502051281, w2: 1.2642839476338967, bias: -3.059963637422819, loss: 0.48103438311867647\n",
      "Epochs: 431, w1: 5.601619231239944, w2: 1.2647838403457903, bias: -3.0633432070571827, loss: 0.48090015012737025\n",
      "Epochs: 432, w1: 5.609041166871851, w2: 1.2652834863436926, bias: -3.066717535472496, loss: 0.48076636992874244\n",
      "Epochs: 433, w1: 5.616450338838852, w2: 1.265782885651639, bias: -3.070086634453216, loss: 0.48063304070691043\n",
      "Epochs: 434, w1: 5.623846776951417, w2: 1.266282038278118, bias: -3.0734505157385166, loss: 0.48050016065438955\n",
      "Epochs: 435, w1: 5.631230510938784, w2: 1.266780944216444, bias: -3.0768091910226523, loss: 0.4803677279720502\n",
      "Epochs: 436, w1: 5.638601570449101, w2: 1.2672796034451275, bias: -3.080162671955323, loss: 0.4802357408690758\n",
      "Epochs: 437, w1: 5.645959985049577, w2: 1.2677780159282355, bias: -3.083510970142029, loss: 0.4801041975629193\n",
      "Epochs: 438, w1: 5.6533057842266325, w2: 1.268276181615746, bias: -3.0868540971444234, loss: 0.4799730962792625\n",
      "Epochs: 439, w1: 5.660638997386048, w2: 1.2687741004438962, bias: -3.0901920644806595, loss: 0.47984243525197257\n",
      "Epochs: 440, w1: 5.667959653853117, w2: 1.269271772335524, bias: -3.0935248836257334, loss: 0.47971221272306086\n",
      "Epochs: 441, w1: 5.675267782872803, w2: 1.2697691972004033, bias: -3.0968525660118202, loss: 0.479582426942642\n",
      "Epochs: 442, w1: 5.68256341360989, w2: 1.2702663749355723, bias: -3.10017512302861, loss: 0.47945307616889143\n",
      "Epochs: 443, w1: 5.689846575149144, w2: 1.2707633054256566, bias: -3.1034925660236348, loss: 0.47932415866800504\n",
      "Epochs: 444, w1: 5.697117296495466, w2: 1.2712599885431861, bias: -3.1068049063025933, loss: 0.47919567271415836\n",
      "Epochs: 445, w1: 5.704375606574057, w2: 1.2717564241489052, bias: -3.1101121551296718, loss: 0.4790676165894656\n",
      "Epochs: 446, w1: 5.711621534230575, w2: 1.2722526120920785, bias: -3.1134143237278593, loss: 0.47893998858393927\n",
      "Epochs: 447, w1: 5.718855108231297, w2: 1.2727485522107893, bias: -3.11671142327926, loss: 0.47881278699545005\n",
      "Epochs: 448, w1: 5.726076357263281, w2: 1.2732442443322336, bias: -3.1200034649254, loss: 0.47868601012968665\n",
      "Epochs: 449, w1: 5.733285309934533, w2: 1.2737396882730079, bias: -3.1232904597675315, loss: 0.478559656300116\n",
      "Epochs: 450, w1: 5.740481994774169, w2: 1.2742348838393918, bias: -3.126572418866932, loss: 0.4784337238279442\n",
      "Epochs: 451, w1: 5.747666440232584, w2: 1.2747298308276258, bias: -3.129849353245201, loss: 0.4783082110420766\n",
      "Epochs: 452, w1: 5.7548386746816185, w2: 1.2752245290241826, bias: -3.1331212738845506, loss: 0.4781831162790787\n",
      "Epochs: 453, w1: 5.761998726414725, w2: 1.2757189782060345, bias: -3.1363881917280945, loss: 0.47805843788313723\n",
      "Epochs: 454, w1: 5.7691466236471385, w2: 1.2762131781409154, bias: -3.139650117680131, loss: 0.4779341742060215\n",
      "Epochs: 455, w1: 5.776282394516048, w2: 1.2767071285875768, bias: -3.1429070626064255, loss: 0.477810323607045\n",
      "Epochs: 456, w1: 5.783406067080766, w2: 1.2772008292960408, bias: -3.146159037334486, loss: 0.47768688445302687\n",
      "Epochs: 457, w1: 5.7905176693229015, w2: 1.2776942800078468, bias: -3.149406052653837, loss: 0.477563855118254\n",
      "Epochs: 458, w1: 5.797617229146531, w2: 1.2781874804562936, bias: -3.152648119316291, loss: 0.47744123398444277\n",
      "Epochs: 459, w1: 5.804704774378376, w2: 1.2786804303666781, bias: -3.155885248036212, loss: 0.47731901944070143\n",
      "Epochs: 460, w1: 5.811780332767974, w2: 1.279173129456528, bias: -3.159117449490781, loss: 0.47719720988349296\n",
      "Epochs: 461, w1: 5.818843931987857, w2: 1.279665577435831, bias: -3.162344734320256, loss: 0.47707580371659736\n",
      "Epochs: 462, w1: 5.825895599633724, w2: 1.2801577740072585, bias: -3.1655671131282275, loss: 0.47695479935107454\n",
      "Epochs: 463, w1: 5.832935363224622, w2: 1.2806497188663866, bias: -3.168784596481871, loss: 0.47683419520522835\n",
      "Epochs: 464, w1: 5.83996325020312, w2: 1.2811414117019115, bias: -3.1719971949122, loss: 0.4767139897045679\n",
      "Epochs: 465, w1: 5.846979287935489, w2: 1.2816328521958615, bias: -3.1752049189143103, loss: 0.47659418128177305\n",
      "Epochs: 466, w1: 5.853983503711883, w2: 1.282124040023804, bias: -3.178407778947626, loss: 0.47647476837665687\n",
      "Epochs: 467, w1: 5.860975924746516, w2: 1.2826149748550504, bias: -3.1816057854361386, loss: 0.47635574943613024\n",
      "Epochs: 468, w1: 5.867956578177841, w2: 1.283105656352854, bias: -3.1847989487686466, loss: 0.47623712291416553\n",
      "Epochs: 469, w1: 5.874925491068735, w2: 1.2835960841746075, bias: -3.1879872792989894, loss: 0.4761188872717605\n",
      "Epochs: 470, w1: 5.881882690406677, w2: 1.2840862579720336, bias: -3.1911707873462802, loss: 0.47600104097690343\n",
      "Epochs: 471, w1: 5.888828203103931, w2: 1.2845761773913742, bias: -3.194349483195135, loss: 0.47588358250453805\n",
      "Epochs: 472, w1: 5.895762055997731, w2: 1.2850658420735745, bias: -3.1975233770958993, loss: 0.4757665103365271\n",
      "Epochs: 473, w1: 5.90268427585046, w2: 1.2855552516544644, bias: -3.2006924792648714, loss: 0.4756498229616183\n",
      "Epochs: 474, w1: 5.909594889349834, w2: 1.2860444057649347, bias: -3.2038567998845244, loss: 0.47553351887540973\n",
      "Epochs: 475, w1: 5.916493923109091, w2: 1.2865333040311129, bias: -3.2070163491037236, loss: 0.4754175965803142\n",
      "Epochs: 476, w1: 5.92338140366717, w2: 1.2870219460745318, bias: -3.2101711370379427, loss: 0.4753020545855261\n",
      "Epochs: 477, w1: 5.930257357488897, w2: 1.287510331512298, bias: -3.2133211737694776, loss: 0.47518689140698617\n",
      "Epochs: 478, w1: 5.937121810965173, w2: 1.2879984599572551, bias: -3.2164664693476563, loss: 0.47507210556734786\n",
      "Epochs: 479, w1: 5.943974790413156, w2: 1.2884863310181445, bias: -3.2196070337890474, loss: 0.47495769559594375\n",
      "Epochs: 480, w1: 5.9508163220764505, w2: 1.2889739442997623, bias: -3.2227428770776654, loss: 0.4748436600287512\n",
      "Epochs: 481, w1: 5.9576464321252915, w2: 1.2894612994031145, bias: -3.2258740091651745, loss: 0.47472999740835936\n",
      "Epochs: 482, w1: 5.964465146656733, w2: 1.2899483959255675, bias: -3.22900043997109, loss: 0.47461670628393565\n",
      "Epochs: 483, w1: 5.971272491694833, w2: 1.2904352334609963, bias: -3.232122179382975, loss: 0.47450378521119263\n",
      "Epochs: 484, w1: 5.978068493190844, w2: 1.29092181159993, bias: -3.2352392372566388, loss: 0.4743912327523551\n",
      "Epochs: 485, w1: 5.984853177023397, w2: 1.2914081299296933, bias: -3.2383516234163294, loss: 0.4742790474761273\n",
      "Epochs: 486, w1: 5.991626568998693, w2: 1.2918941880345476, bias: -3.241459347654926, loss: 0.47416722795765964\n",
      "Epochs: 487, w1: 5.998388694850688, w2: 1.2923799854958258, bias: -3.2445624197341285, loss: 0.47405577277851824\n",
      "Epochs: 488, w1: 6.005139580241287, w2: 1.2928655218920668, bias: -3.247660849384644, loss: 0.4739446805266498\n",
      "Epochs: 489, w1: 6.011879250760523, w2: 1.2933507967991473, bias: -3.2507546463063735, loss: 0.4738339497963519\n",
      "Epochs: 490, w1: 6.018607731926757, w2: 1.2938358097904092, bias: -3.253843820168593, loss: 0.4737235791882401\n",
      "Epochs: 491, w1: 6.025325049186859, w2: 1.294320560436786, bias: -3.256928380610136, loss: 0.47361356730921567\n",
      "Epochs: 492, w1: 6.0320312279164, w2: 1.294805048306926, bias: -3.260008337239573, loss: 0.4735039127724351\n",
      "Epochs: 493, w1: 6.0387262934198445, w2: 1.2952892729673133, bias: -3.2630836996353874, loss: 0.4733946141972782\n",
      "Epochs: 494, w1: 6.045410270930734, w2: 1.2957732339823855, bias: -3.26615447734615, loss: 0.4732856702093171\n",
      "Epochs: 495, w1: 6.052083185611882, w2: 1.2962569309146499, bias: -3.269220679890693, loss: 0.4731770794402845\n",
      "Epochs: 496, w1: 6.05874506255556, w2: 1.2967403633247971, bias: -3.2722823167582815, loss: 0.4730688405280428\n",
      "Epochs: 497, w1: 6.065395926783691, w2: 1.2972235307718119, bias: -3.275339397408782, loss: 0.4729609521165545\n",
      "Epochs: 498, w1: 6.0720358032480375, w2: 1.2977064328130814, bias: -3.2783919312728296, loss: 0.4728534128558509\n",
      "Epochs: 499, w1: 6.078664716830392, w2: 1.298189069004503, bias: -3.281439927751994, loss: 0.4727462214020012\n",
      "Epochs: 500, w1: 6.0852826923427665, w2: 1.2986714389005876, bias: -3.284483396218944, loss: 0.4726393764170826\n",
      "Epochs: 501, w1: 6.0918897545275845, w2: 1.2991535420545617, bias: -3.2875223460176075, loss: 0.47253287656915127\n",
      "Epochs: 502, w1: 6.09848592805787, w2: 1.2996353780184677, bias: -3.290556786463333, loss: 0.4724267205322102\n",
      "Epochs: 503, w1: 6.105071237537438, w2: 1.300116946343262, bias: -3.2935867268430488, loss: 0.4723209069861817\n",
      "Epochs: 504, w1: 6.111645707501086, w2: 1.3005982465789099, bias: -3.296612176415418, loss: 0.47221543461687626\n",
      "Epochs: 505, w1: 6.118209362414783, w2: 1.30107927827448, bias: -3.299633144410995, loss: 0.4721103021159637\n",
      "Epochs: 506, w1: 6.124762226675859, w2: 1.301560040978236, bias: -3.302649640032379, loss: 0.47200550818094417\n",
      "Epochs: 507, w1: 6.1313043246131995, w2: 1.302040534237726, bias: -3.3056616724543635, loss: 0.4719010515151185\n",
      "Epochs: 508, w1: 6.137835680487432, w2: 1.3025207575998705, bias: -3.3086692508240905, loss: 0.4717969308275588\n",
      "Epochs: 509, w1: 6.144356318491116, w2: 1.3030007106110488, bias: -3.3116723842611964, loss: 0.47169314483308145\n",
      "Epochs: 510, w1: 6.150866262748938, w2: 1.3034803928171823, bias: -3.3146710818579592, loss: 0.47158969225221625\n",
      "Epochs: 511, w1: 6.157365537317895, w2: 1.3039598037638176, bias: -3.3176653526794455, loss: 0.471486571811179\n",
      "Epochs: 512, w1: 6.16385416618749, w2: 1.3044389429962064, bias: -3.320655205763653, loss: 0.4713837822418436\n",
      "Epochs: 513, w1: 6.170332173279922, w2: 1.3049178100593843, bias: -3.323640650121655, loss: 0.4712813222817125\n",
      "Epochs: 514, w1: 6.176799582450271, w2: 1.3053964044982482, bias: -3.326621694737739, loss: 0.4711791906738899\n",
      "Epochs: 515, w1: 6.183256417486693, w2: 1.3058747258576309, bias: -3.329598348569549, loss: 0.47107738616705286\n",
      "Epochs: 516, w1: 6.189702702110609, w2: 1.306352773682375, bias: -3.332570620548222, loss: 0.47097590751542495\n",
      "Epochs: 517, w1: 6.1961384599768925, w2: 1.3068305475174056, bias: -3.3355385195785257, loss: 0.4708747534787465\n",
      "Epochs: 518, w1: 6.202563714674061, w2: 1.3073080469077993, bias: -3.3385020545389934, loss: 0.4707739228222497\n",
      "Epochs: 519, w1: 6.208978489724464, w2: 1.3077852713988545, bias: -3.3414612342820593, loss: 0.4706734143166286\n",
      "Epochs: 520, w1: 6.215382808584473, w2: 1.3082622205361574, bias: -3.3444160676341896, loss: 0.4705732267380142\n",
      "Epochs: 521, w1: 6.2217766946446735, w2: 1.3087388938656483, bias: -3.347366563396016, loss: 0.47047335886794633\n",
      "Epochs: 522, w1: 6.228160171230049, w2: 1.309215290933686, bias: -3.350312730342464, loss: 0.4703738094933467\n",
      "Epochs: 523, w1: 6.2345332616001725, w2: 1.30969141128711, bias: -3.353254577222883, loss: 0.47027457740649264\n",
      "Epochs: 524, w1: 6.240895988949396, w2: 1.3101672544733027, bias: -3.3561921127611734, loss: 0.47017566140499034\n",
      "Epochs: 525, w1: 6.247248376407038, w2: 1.3106428200402485, bias: -3.3591253456559134, loss: 0.47007706029174834\n",
      "Epochs: 526, w1: 6.253590447037571, w2: 1.3111181075365923, bias: -3.3620542845804837, loss: 0.46997877287495116\n",
      "Epochs: 527, w1: 6.259922223840812, w2: 1.3115931165116976, bias: -3.3649789381831923, loss: 0.46988079796803306\n",
      "Epochs: 528, w1: 6.266243729752108, w2: 1.3120678465157016, bias: -3.3678993150873966, loss: 0.46978313438965286\n",
      "Epochs: 529, w1: 6.272554987642524, w2: 1.3125422970995695, bias: -3.370815423891625, loss: 0.46968578096366664\n",
      "Epochs: 530, w1: 6.278856020319033, w2: 1.3130164678151484, bias: -3.3737272731696972, loss: 0.4695887365191028\n",
      "Epochs: 531, w1: 6.285146850524701, w2: 1.3134903582152189, bias: -3.376634871470845, loss: 0.46949199989013696\n",
      "Epochs: 532, w1: 6.291427500938874, w2: 1.3139639678535457, bias: -3.379538227319828, loss: 0.46939556991606524\n",
      "Epochs: 533, w1: 6.297697994177367, w2: 1.3144372962849276, bias: -3.382437349217053, loss: 0.46929944544128016\n",
      "Epochs: 534, w1: 6.30395835279265, w2: 1.314910343065245, bias: -3.3853322456386885, loss: 0.46920362531524423\n",
      "Epochs: 535, w1: 6.310208599274031, w2: 1.3153831077515075, bias: -3.3882229250367804, loss: 0.46910810839246636\n",
      "Epochs: 536, w1: 6.316448756047846, w2: 1.3158555899019002, bias: -3.391109395839366, loss: 0.4690128935324752\n",
      "Epochs: 537, w1: 6.322678845477644, w2: 1.3163277890758283, bias: -3.3939916664505856, loss: 0.46891797959979603\n",
      "Epochs: 538, w1: 6.328898889864372, w2: 1.3167997048339601, bias: -3.396869745250796, loss: 0.46882336546392483\n",
      "Epochs: 539, w1: 6.335108911446562, w2: 1.3172713367382711, bias: -3.39974364059668, loss: 0.4687290499993043\n",
      "Epochs: 540, w1: 6.341308932400511, w2: 1.3177426843520839, bias: -3.402613360821357, loss: 0.46863503208529944\n",
      "Epochs: 541, w1: 6.347498974840475, w2: 1.31821374724011, bias: -3.40547891423449, loss: 0.4685413106061731\n",
      "Epochs: 542, w1: 6.353679060818843, w2: 1.3186845249684889, bias: -3.4083403091223965, loss: 0.4684478844510624\n",
      "Epochs: 543, w1: 6.359849212326329, w2: 1.319155017104826, bias: -3.4111975537481527, loss: 0.46835475251395364\n",
      "Epochs: 544, w1: 6.366009451292152, w2: 1.3196252232182313, bias: -3.4140506563517, loss: 0.4682619136936594\n",
      "Epochs: 545, w1: 6.372159799584222, w2: 1.3200951428793544, bias: -3.4168996251499513, loss: 0.46816936689379446\n",
      "Epochs: 546, w1: 6.378300279009321, w2: 1.3205647756604213, bias: -3.4197444683368934, loss: 0.468077111022752\n",
      "Epochs: 547, w1: 6.384430911313289, w2: 1.3210341211352685, bias: -3.42258519408369, loss: 0.4679851449936805\n",
      "Epochs: 548, w1: 6.390551718181203, w2: 1.3215031788793767, bias: -3.425421810538787, loss: 0.4678934677244596\n",
      "Epochs: 549, w1: 6.396662721237561, w2: 1.3219719484699035, bias: -3.428254325828008, loss: 0.4678020781376778\n",
      "Epochs: 550, w1: 6.402763942046467, w2: 1.3224404294857153, bias: -3.4310827480546617, loss: 0.4677109751606089\n",
      "Epochs: 551, w1: 6.408855402111808, w2: 1.3229086215074184, bias: -3.4339070852996363, loss: 0.4676201577251886\n",
      "Epochs: 552, w1: 6.414937122877438, w2: 1.3233765241173894, bias: -3.4367273456215006, loss: 0.46752962476799204\n",
      "Epochs: 553, w1: 6.421009125727359, w2: 1.323844136899804, bias: -3.4395435370566014, loss: 0.4674393752302116\n",
      "Epochs: 554, w1: 6.427071431985901, w2: 1.324311459440666, bias: -3.4423556676191605, loss: 0.46734940805763275\n",
      "Epochs: 555, w1: 6.433124062917903, w2: 1.3247784913278347, bias: -3.4451637453013713, loss: 0.467259722200613\n",
      "Epochs: 556, w1: 6.439167039728893, w2: 1.3252452321510517, bias: -3.4479677780734943, loss: 0.46717031661405883\n",
      "Epochs: 557, w1: 6.445200383565267, w2: 1.3257116815019674, bias: -3.450767773883951, loss: 0.4670811902574035\n",
      "Epochs: 558, w1: 6.451224115514471, w2: 1.326177838974166, bias: -3.45356374065942, loss: 0.4669923420945848\n",
      "Epochs: 559, w1: 6.457238256605174, w2: 1.3266437041631909, bias: -3.4563556863049265, loss: 0.4669037710940232\n",
      "Epochs: 560, w1: 6.463242827807454, w2: 1.327109276666567, bias: -3.459143618703939, loss: 0.46681547622859987\n",
      "Epochs: 561, w1: 6.469237850032971, w2: 1.3275745560838257, bias: -3.461927545718457, loss: 0.46672745647563435\n",
      "Epochs: 562, w1: 6.475223344135148, w2: 1.3280395420165256, bias: -3.4647074751891043, loss: 0.4666397108168644\n",
      "Epochs: 563, w1: 6.481199330909346, w2: 1.328504234068276, bias: -3.4674834149352187, loss: 0.46655223823842235\n",
      "Epochs: 564, w1: 6.487165831093044, w2: 1.3289686318447564, bias: -3.4702553727549414, loss: 0.4664650377308149\n",
      "Epochs: 565, w1: 6.493122865366014, w2: 1.3294327349537383, bias: -3.4730233564253052, loss: 0.46637810828890197\n",
      "Epochs: 566, w1: 6.4990704543504965, w2: 1.3298965430051037, bias: -3.4757873737023233, loss: 0.4662914489118743\n",
      "Epochs: 567, w1: 6.505008618611378, w2: 1.3303600556108655, bias: -3.478547432321076, loss: 0.4662050586032336\n",
      "Epochs: 568, w1: 6.510937378656368, w2: 1.3308232723851843, bias: -3.481303539995798, loss: 0.4661189363707709\n",
      "Epochs: 569, w1: 6.51685675493617, w2: 1.3312861929443882, bias: -3.484055704419963, loss: 0.46603308122654546\n",
      "Epochs: 570, w1: 6.5227667678446615, w2: 1.3317488169069889, bias: -3.486803933266371, loss: 0.4659474921868645\n",
      "Epochs: 571, w1: 6.528667437719065, w2: 1.3322111438936985, bias: -3.489548234187232, loss: 0.4658621682722623\n",
      "Epochs: 572, w1: 6.534558784840122, w2: 1.3326731735274457, bias: -3.4922886148142496, loss: 0.46577710850747955\n",
      "Epochs: 573, w1: 6.540440829432271, w2: 1.3331349054333914, bias: -3.4950250827587053, loss: 0.4656923119214429\n",
      "Epochs: 574, w1: 6.5463135916638135, w2: 1.3335963392389436, bias: -3.49775764561154, loss: 0.4656077775472447\n",
      "Epochs: 575, w1: 6.552177091647094, w2: 1.3340574745737719, bias: -3.5004863109434368, loss: 0.4655235044221227\n",
      "Epochs: 576, w1: 6.558031349438668, w2: 1.3345183110698213, bias: -3.503211086304903, loss: 0.46543949158744036\n",
      "Epochs: 577, w1: 6.563876385039477, w2: 1.3349788483613254, bias: -3.50593197922635, loss: 0.4653557380886658\n",
      "Epochs: 578, w1: 6.569712218395018, w2: 1.3354390860848193, bias: -3.508648997218175, loss: 0.4652722429753529\n",
      "Epochs: 579, w1: 6.575538869395514, w2: 1.3358990238791526, bias: -3.5113621477708383, loss: 0.4651890053011209\n",
      "Epochs: 580, w1: 6.581356357876088, w2: 1.3363586613854999, bias: -3.5140714383549447, loss: 0.4651060241236349\n",
      "Epochs: 581, w1: 6.587164703616932, w2: 1.3368179982473731, bias: -3.5167768764213214, loss: 0.4650232985045863\n",
      "Epochs: 582, w1: 6.592963926343477, w2: 1.3372770341106326, bias: -3.519478469401095, loss: 0.46494082750967336\n",
      "Epochs: 583, w1: 6.598754045726561, w2: 1.3377357686234965, bias: -3.5221762247057704, loss: 0.4648586102085813\n",
      "Epochs: 584, w1: 6.604535081382601, w2: 1.3381942014365515, bias: -3.5248701497273056, loss: 0.46477664567496374\n",
      "Epochs: 585, w1: 6.610307052873761, w2: 1.338652332202762, bias: -3.5275602518381906, loss: 0.46469493298642295\n",
      "Epochs: 586, w1: 6.616069979708118, w2: 1.339110160577479, bias: -3.530246538391521, loss: 0.464613471224491\n",
      "Epochs: 587, w1: 6.621823881339832, w2: 1.3395676862184491, bias: -3.532929016721074, loss: 0.4645322594746108\n",
      "Epochs: 588, w1: 6.627568777169316, w2: 1.3400249087858231, bias: -3.535607694141383, loss: 0.46445129682611697\n",
      "Epochs: 589, w1: 6.633304686543397, w2: 1.3404818279421624, bias: -3.538282577947812, loss: 0.4643705823722174\n",
      "Epochs: 590, w1: 6.639031628755488, w2: 1.3409384433524478, bias: -3.540953675416629, loss: 0.46429011520997415\n",
      "Epochs: 591, w1: 6.644749623045751, w2: 1.3413947546840854, bias: -3.543620993805078, loss: 0.46420989444028565\n",
      "Epochs: 592, w1: 6.650458688601266, w2: 1.341850761606914, bias: -3.5462845403514547, loss: 0.4641299191678669\n",
      "Epochs: 593, w1: 6.6561588445561926, w2: 1.3423064637932107, bias: -3.5489443222751746, loss: 0.46405018850123214\n",
      "Epochs: 594, w1: 6.661850109991937, w2: 1.3427618609176974, bias: -3.551600346776848, loss: 0.4639707015526765\n",
      "Epochs: 595, w1: 6.667532503937316, w2: 1.3432169526575455, bias: -3.5542526210383496, loss: 0.46389145743825727\n",
      "Epochs: 596, w1: 6.673206045368723, w2: 1.3436717386923815, bias: -3.556901152222889, loss: 0.4638124552777761\n",
      "Epochs: 597, w1: 6.67887075321029, w2: 1.3441262187042917, bias: -3.5595459474750806, loss: 0.4637336941947607\n",
      "Epochs: 598, w1: 6.684526646334047, w2: 1.3445803923778263, bias: -3.5621870139210148, loss: 0.46365517331644773\n",
      "Epochs: 599, w1: 6.690173743560093, w2: 1.345034259400004, bias: -3.5648243586683264, loss: 0.463576891773764\n",
      "Epochs: 600, w1: 6.695812063656752, w2: 1.3454878194603153, bias: -3.5674579888062627, loss: 0.4634988487013096\n",
      "Epochs: 601, w1: 6.701441625340737, w2: 1.3459410722507261, bias: -3.5700879114057527, loss: 0.463421043237339\n",
      "Epochs: 602, w1: 6.707062447277312, w2: 1.346394017465681, bias: -3.5727141335194745, loss: 0.46334347452374536\n",
      "Epochs: 603, w1: 6.712674548080449, w2: 1.3468466548021052, bias: -3.5753366621819236, loss: 0.46326614170604147\n",
      "Epochs: 604, w1: 6.718277946312997, w2: 1.3472989839594083, bias: -3.577955504409479, loss: 0.4631890439333431\n",
      "Epochs: 605, w1: 6.723872660486833, w2: 1.3477510046394856, bias: -3.580570667200469, loss: 0.46311218035835194\n",
      "Epochs: 606, w1: 6.729458709063027, w2: 1.3482027165467205, bias: -3.58318215753524, loss: 0.4630355501373376\n",
      "Epochs: 607, w1: 6.735036110452, w2: 1.3486541193879855, bias: -3.5857899823762196, loss: 0.46295915243012153\n",
      "Epochs: 608, w1: 6.740604883013682, w2: 1.3491052128726442, bias: -3.588394148667983, loss: 0.46288298640005915\n",
      "Epochs: 609, w1: 6.746165045057672, w2: 1.3495559967125517, bias: -3.5909946633373178, loss: 0.4628070512140241\n",
      "Epochs: 610, w1: 6.751716614843393, w2: 1.350006470622056, bias: -3.5935915332932886, loss: 0.4627313460423894\n",
      "Epochs: 611, w1: 6.757259610580255, w2: 1.3504566343179985, bias: -3.5961847654273007, loss: 0.4626558700590135\n",
      "Epochs: 612, w1: 6.7627940504278055, w2: 1.3509064875197139, bias: -3.598774366613164, loss: 0.462580622441221\n",
      "Epochs: 613, w1: 6.768319952495889, w2: 1.3513560299490301, bias: -3.601360343707156, loss: 0.46250560236978777\n",
      "Epochs: 614, w1: 6.7738373348448055, w2: 1.3518052613302691, bias: -3.603942703548086, loss: 0.46243080902892364\n",
      "Epochs: 615, w1: 6.779346215485461, w2: 1.3522541813902451, bias: -3.606521452957355, loss: 0.46235624160625705\n",
      "Epochs: 616, w1: 6.7848466123795275, w2: 1.3527027898582646, bias: -3.6090965987390202, loss: 0.46228189929281727\n",
      "Epochs: 617, w1: 6.790338543439596, w2: 1.3531510864661256, bias: -3.611668147679856, loss: 0.46220778128301904\n",
      "Epochs: 618, w1: 6.79582202652933, w2: 1.353599070948116, bias: -3.6142361065494146, loss: 0.4621338867746472\n",
      "Epochs: 619, w1: 6.8012970794636205, w2: 1.3540467430410128, bias: -3.6168004821000888, loss: 0.4620602149688388\n",
      "Epochs: 620, w1: 6.806763720008738, w2: 1.3544941024840795, bias: -3.6193612810671705, loss: 0.461986765070069\n",
      "Epochs: 621, w1: 6.812221965882489, w2: 1.354941149019066, bias: -3.6219185101689124, loss: 0.46191353628613413\n",
      "Epochs: 622, w1: 6.817671834754364, w2: 1.3553878823902048, bias: -3.624472176106587, loss: 0.46184052782813595\n",
      "Epochs: 623, w1: 6.8231133442456935, w2: 1.3558343023442103, bias: -3.627022285564547, loss: 0.46176773891046635\n",
      "Epochs: 624, w1: 6.828546511929797, w2: 1.3562804086302753, bias: -3.629568845210284, loss: 0.46169516875079175\n",
      "Epochs: 625, w1: 6.833971355332134, w2: 1.3567262010000691, bias: -3.632111861694488, loss: 0.46162281657003706\n",
      "Epochs: 626, w1: 6.8393878919304605, w2: 1.3571716792077348, bias: -3.6346513416511046, loss: 0.4615506815923707\n",
      "Epochs: 627, w1: 6.84479613915497, w2: 1.357616843009886, bias: -3.6371872916973946, loss: 0.46147876304518926\n",
      "Epochs: 628, w1: 6.850196114388449, w2: 1.3580616921656037, bias: -3.639719718433991, loss: 0.4614070601591015\n",
      "Epochs: 629, w1: 6.855587834966429, w2: 1.3585062264364332, bias: -3.6422486284449564, loss: 0.46133557216791377\n",
      "Epochs: 630, w1: 6.860971318177328, w2: 1.3589504455863806, bias: -3.6447740282978414, loss: 0.4612642983086154\n",
      "Epochs: 631, w1: 6.866346581262606, w2: 1.3593943493819092, bias: -3.6472959245437395, loss: 0.46119323782136185\n",
      "Epochs: 632, w1: 6.8717136414169095, w2: 1.3598379375919356, bias: -3.649814323717346, loss: 0.46112238994946214\n",
      "Epochs: 633, w1: 6.877072515788219, w2: 1.360281209987826, bias: -3.652329232337012, loss: 0.4610517539393614\n",
      "Epochs: 634, w1: 6.882423221477999, w2: 1.360724166343392, bias: -3.6548406569048013, loss: 0.4609813290406283\n",
      "Epochs: 635, w1: 6.887765775541341, w2: 1.3611668064348859, bias: -3.6573486039065464, loss: 0.460911114505939\n",
      "Epochs: 636, w1: 6.893100194987113, w2: 1.361609130040997, bias: -3.6598530798119033, loss: 0.4608411095910628\n",
      "Epochs: 637, w1: 6.898426496778105, w2: 1.362051136942847, bias: -3.6623540910744063, loss: 0.4607713135548472\n",
      "Epochs: 638, w1: 6.90374469783117, w2: 1.3624928269239847, bias: -3.664851644131523, loss: 0.4607017256592046\n",
      "Epochs: 639, w1: 6.9090548150173765, w2: 1.3629341997703819, bias: -3.6673457454047083, loss: 0.46063234516909635\n",
      "Epochs: 640, w1: 6.914356865162147, w2: 1.363375255270428, bias: -3.6698364012994587, loss: 0.460563171352519\n",
      "Epochs: 641, w1: 6.919650865045405, w2: 1.363815993214925, bias: -3.672323618205367, loss: 0.4604942034804907\n",
      "Epochs: 642, w1: 6.924936831401717, w2: 1.3642564133970827, bias: -3.674807402496174, loss: 0.46042544082703557\n",
      "Epochs: 643, w1: 6.930214780920437, w2: 1.364696515612513, bias: -3.6772877605298233, loss: 0.46035688266917096\n",
      "Epochs: 644, w1: 6.935484730245848, w2: 1.3651362996592245, bias: -3.679764698648513, loss: 0.4602885282868922\n",
      "Epochs: 645, w1: 6.940746695977308, w2: 1.3655757653376166, bias: -3.6822382231787487, loss: 0.4602203769631595\n",
      "Epochs: 646, w1: 6.946000694669385, w2: 1.3660149124504748, bias: -3.6847083404313974, loss: 0.46015242798388395\n",
      "Epochs: 647, w1: 6.951246742832005, w2: 1.366453740802964, bias: -3.687175056701737, loss: 0.4600846806379126\n",
      "Epochs: 648, w1: 6.95648485693059, w2: 1.3668922502026228, bias: -3.6896383782695095, loss: 0.4600171342170164\n",
      "Epochs: 649, w1: 6.9617150533861984, w2: 1.3673304404593583, bias: -3.692098311398973, loss: 0.4599497880158747\n",
      "Epochs: 650, w1: 6.966937348575667, w2: 1.3677683113854384, bias: -3.694554862338952, loss: 0.4598826413320634\n",
      "Epochs: 651, w1: 6.972151758831747, w2: 1.3682058627954876, bias: -3.6970080373228886, loss: 0.45981569346603995\n",
      "Epochs: 652, w1: 6.977358300443249, w2: 1.368643094506479, bias: -3.699457842568894, loss: 0.4597489437211302\n",
      "Epochs: 653, w1: 6.982556989655175, w2: 1.3690800063377284, bias: -3.701904284279798, loss: 0.45968239140351597\n",
      "Epochs: 654, w1: 6.987747842668864, w2: 1.3695165981108888, bias: -3.7043473686431994, loss: 0.45961603582222\n",
      "Epochs: 655, w1: 6.992930875642124, w2: 1.3699528696499426, bias: -3.706787101831517, loss: 0.4595498762890941\n",
      "Epochs: 656, w1: 6.99810610468937, w2: 1.3703888207811952, bias: -3.7092234900020378, loss: 0.45948391211880524\n",
      "Epochs: 657, w1: 7.0032735458817665, w2: 1.3708244513332688, bias: -3.7116565392969676, loss: 0.45941814262882263\n",
      "Epochs: 658, w1: 7.008433215247358, w2: 1.3712597611370954, bias: -3.7140862558434797, loss: 0.45935256713940426\n",
      "Epochs: 659, w1: 7.013585128771208, w2: 1.3716947500259091, bias: -3.7165126457537636, loss: 0.45928718497358473\n",
      "Epochs: 660, w1: 7.018729302395535, w2: 1.3721294178352406, bias: -3.7189357151250744, loss: 0.45922199545716147\n",
      "Epochs: 661, w1: 7.023865752019847, w2: 1.3725637644029085, bias: -3.721355470039781, loss: 0.4591569979186824\n",
      "Epochs: 662, w1: 7.0289944935010755, w2: 1.3729977895690137, bias: -3.723771916565414, loss: 0.4590921916894322\n",
      "Epochs: 663, w1: 7.034115542653712, w2: 1.3734314931759315, bias: -3.7261850607547147, loss: 0.4590275761034209\n",
      "Epochs: 664, w1: 7.039228915249942, w2: 1.373864875068304, bias: -3.728594908645681, loss: 0.45896315049737063\n",
      "Epochs: 665, w1: 7.044334627019776, w2: 1.3742979350930333, bias: -3.7310014662616173, loss: 0.45889891421070234\n",
      "Epochs: 666, w1: 7.049432693651184, w2: 1.374730673099274, bias: -3.73340473961118, loss: 0.45883486658552447\n",
      "Epochs: 667, w1: 7.054523130790231, w2: 1.3751630889384263, bias: -3.7358047346884247, loss: 0.4587710069666194\n",
      "Epochs: 668, w1: 7.0596059540412055, w2: 1.3755951824641268, bias: -3.7382014574728544, loss: 0.4587073347014316\n",
      "Epochs: 669, w1: 7.064681178966753, w2: 1.3760269535322431, bias: -3.7405949139294647, loss: 0.4586438491400551\n",
      "Epochs: 670, w1: 7.069748821088006, w2: 1.3764584020008646, bias: -3.742985110008791, loss: 0.4585805496352214\n",
      "Epochs: 671, w1: 7.07480889588472, w2: 1.3768895277302955, bias: -3.7453720516469535, loss: 0.45851743554228713\n",
      "Epochs: 672, w1: 7.079861418795397, w2: 1.377320330583047, bias: -3.7477557447657053, loss: 0.4584545062192213\n",
      "Epochs: 673, w1: 7.08490640521742, w2: 1.3777508104238296, bias: -3.7501361952724763, loss: 0.45839176102659435\n",
      "Epochs: 674, w1: 7.089943870507183, w2: 1.3781809671195449, bias: -3.752513409060419, loss: 0.4583291993275653\n",
      "Epochs: 675, w1: 7.094973829980217, w2: 1.378610800539278, bias: -3.7548873920084542, loss: 0.4582668204878697\n",
      "Epochs: 676, w1: 7.099996298911326, w2: 1.37904031055429, bias: -3.757258149981316, loss: 0.45820462387580835\n",
      "Epochs: 677, w1: 7.105011292534705, w2: 1.3794694970380095, bias: -3.759625688829597, loss: 0.45814260886223485\n",
      "Epochs: 678, w1: 7.110018826044078, w2: 1.3798983598660242, bias: -3.7619900143897924, loss: 0.4580807748205444\n",
      "Epochs: 679, w1: 7.115018914592819, w2: 1.380326898916074, bias: -3.764351132484344, loss: 0.4580191211266607\n",
      "Epochs: 680, w1: 7.120011573294085, w2: 1.3807551140680419, bias: -3.766709048921686, loss: 0.45795764715902654\n",
      "Epochs: 681, w1: 7.124996817220936, w2: 1.3811830052039467, bias: -3.7690637694962876, loss: 0.45789635229859016\n",
      "Epochs: 682, w1: 7.129974661406466, w2: 1.3816105722079342, bias: -3.771415299988698, loss: 0.4578352359287947\n",
      "Epochs: 683, w1: 7.1349451208439305, w2: 1.382037814966269, bias: -3.7737636461655892, loss: 0.45777429743556597\n",
      "Epochs: 684, w1: 7.139908210486866, w2: 1.3824647333673274, bias: -3.7761088137798, loss: 0.4577135362073024\n",
      "Epochs: 685, w1: 7.144863945249223, w2: 1.3828913273015875, bias: -3.7784508085703776, loss: 0.4576529516348619\n",
      "Epochs: 686, w1: 7.149812340005483, w2: 1.383317596661622, bias: -3.7807896362626243, loss: 0.45759254311155195\n",
      "Epochs: 687, w1: 7.154753409590788, w2: 1.3837435413420898, bias: -3.7831253025681364, loss: 0.45753231003311734\n",
      "Epochs: 688, w1: 7.159687168801065, w2: 1.384169161239727, bias: -3.785457813184849, loss: 0.45747225179772977\n",
      "Epochs: 689, w1: 7.164613632393142, w2: 1.38459445625334, bias: -3.7877871737970783, loss: 0.4574123678059763\n",
      "Epochs: 690, w1: 7.169532815084883, w2: 1.3850194262837954, bias: -3.7901133900755637, loss: 0.45735265746084797\n",
      "Epochs: 691, w1: 7.174444731555301, w2: 1.3854440712340124, bias: -3.7924364676775095, loss: 0.4572931201677299\n",
      "Epochs: 692, w1: 7.1793493964446835, w2: 1.3858683910089546, bias: -3.7947564122466275, loss: 0.45723375533438804\n",
      "Epochs: 693, w1: 7.184246824354715, w2: 1.3862923855156213, bias: -3.797073229413178, loss: 0.4571745623709615\n",
      "Epochs: 694, w1: 7.1891370298486, w2: 1.3867160546630388, bias: -3.799386924794012, loss: 0.4571155406899489\n",
      "Epochs: 695, w1: 7.194020027451179, w2: 1.3871393983622526, bias: -3.801697503992613, loss: 0.45705668970619845\n",
      "Epochs: 696, w1: 7.198895831649056, w2: 1.387562416526318, bias: -3.804004972599136, loss: 0.45699800883689756\n",
      "Epochs: 697, w1: 7.203764456890712, w2: 1.3879851090702926, bias: -3.8063093361904508, loss: 0.4569394975015623\n",
      "Epochs: 698, w1: 7.208625917586631, w2: 1.3884074759112266, bias: -3.8086106003301823, loss: 0.4568811551220257\n",
      "Epochs: 699, w1: 7.213480228109415, w2: 1.388829516968155, bias: -3.810908770568751, loss: 0.45682298112242814\n",
      "Epochs: 700, w1: 7.2183274027939035, w2: 1.3892512321620893, bias: -3.8132038524434124, loss: 0.4567649749292065\n",
      "Epochs: 701, w1: 7.223167455937297, w2: 1.3896726214160084, bias: -3.8154958514782993, loss: 0.45670713597108326\n",
      "Epochs: 702, w1: 7.228000401799269, w2: 1.3900936846548502, bias: -3.8177847731844605, loss: 0.45664946367905707\n",
      "Epochs: 703, w1: 7.232826254602088, w2: 1.3905144218055026, bias: -3.820070623059901, loss: 0.45659195748639136\n",
      "Epochs: 704, w1: 7.237645028530734, w2: 1.3909348327967959, bias: -3.8223534065896216, loss: 0.4565346168286048\n",
      "Epochs: 705, w1: 7.242456737733014, w2: 1.3913549175594933, bias: -3.8246331292456595, loss: 0.45647744114345984\n",
      "Epochs: 706, w1: 7.247261396319681, w2: 1.3917746760262826, bias: -3.826909796487127, loss: 0.45642042987095444\n",
      "Epochs: 707, w1: 7.252059018364551, w2: 1.3921941081317675, bias: -3.829183413760251, loss: 0.45636358245330955\n",
      "Epochs: 708, w1: 7.2568496179046145, w2: 1.3926132138124594, bias: -3.831453986498411, loss: 0.4563068983349614\n",
      "Epochs: 709, w1: 7.2616332089401565, w2: 1.393031993006768, bias: -3.8337215201221806, loss: 0.4562503769625494\n",
      "Epochs: 710, w1: 7.266409805434871, w2: 1.3934504456549934, bias: -3.835986020039363, loss: 0.45619401778490737\n",
      "Epochs: 711, w1: 7.271179421315973, w2: 1.393868571699317, bias: -3.8382474916450335, loss: 0.45613782025305266\n",
      "Epochs: 712, w1: 7.275942070474318, w2: 1.3942863710837936, bias: -3.8405059403215738, loss: 0.45608178382017767\n",
      "Epochs: 713, w1: 7.28069776676451, w2: 1.3947038437543413, bias: -3.842761371438713, loss: 0.45602590794163816\n",
      "Epochs: 714, w1: 7.285446524005018, w2: 1.3951209896587344, bias: -3.845013790353566, loss: 0.4559701920749449\n",
      "Epochs: 715, w1: 7.290188355978293, w2: 1.3955378087465942, bias: -3.8472632024106694, loss: 0.455914635679753\n",
      "Epochs: 716, w1: 7.294923276430873, w2: 1.3959543009693798, bias: -3.849509612942021, loss: 0.45585923821785285\n",
      "Epochs: 717, w1: 7.299651299073502, w2: 1.3963704662803806, bias: -3.851753027267117, loss: 0.45580399915316006\n",
      "Epochs: 718, w1: 7.304372437581239, w2: 1.3967863046347069, bias: -3.8539934506929896, loss: 0.4557489179517056\n",
      "Epochs: 719, w1: 7.309086705593571, w2: 1.3972018159892812, bias: -3.8562308885142444, loss: 0.4556939940816273\n",
      "Epochs: 720, w1: 7.313794116714524, w2: 1.3976170003028303, bias: -3.858465346013097, loss: 0.4556392270131587\n",
      "Epochs: 721, w1: 7.318494684512774, w2: 1.3980318575358759, bias: -3.860696828459411, loss: 0.45558461621862106\n",
      "Epochs: 722, w1: 7.323188422521756, w2: 1.3984463876507263, bias: -3.862925341110735, loss: 0.4555301611724136\n",
      "Epochs: 723, w1: 7.327875344239779, w2: 1.3988605906114682, bias: -3.8651508892123374, loss: 0.455475861351003\n",
      "Epochs: 724, w1: 7.332555463130129, w2: 1.3992744663839574, bias: -3.867373477997246, loss: 0.455421716232916\n",
      "Epochs: 725, w1: 7.337228792621184, w2: 1.3996880149358106, bias: -3.869593112686282, loss: 0.455367725298728\n",
      "Epochs: 726, w1: 7.341895346106522, w2: 1.400101236236397, bias: -3.8718097984880986, loss: 0.4553138880310559\n",
      "Epochs: 727, w1: 7.346555136945027, w2: 1.4005141302568294, bias: -3.874023540599214, loss: 0.45526020391454697\n",
      "Epochs: 728, w1: 7.351208178461001, w2: 1.4009266969699556, bias: -3.876234344204051, loss: 0.4552066724358718\n",
      "Epochs: 729, w1: 7.355854483944269, w2: 1.4013389363503506, bias: -3.878442214474971, loss: 0.45515329308371266\n",
      "Epochs: 730, w1: 7.360494066650291, w2: 1.4017508483743069, bias: -3.8806471565723086, loss: 0.45510006534875697\n",
      "Epochs: 731, w1: 7.365126939800261, w2: 1.4021624330198266, bias: -3.8828491756444103, loss: 0.45504698872368654\n",
      "Epochs: 732, w1: 7.369753116581224, w2: 1.4025736902666133, bias: -3.8850482768276673, loss: 0.4549940627031692\n",
      "Epochs: 733, w1: 7.374372610146176, w2: 1.4029846200960625, bias: -3.8872444652465523, loss: 0.45494128678385093\n",
      "Epochs: 734, w1: 7.378985433614172, w2: 1.4033952224912543, bias: -3.8894377460136544, loss: 0.4548886604643444\n",
      "Epochs: 735, w1: 7.3835916000704325, w2: 1.4038054974369443, bias: -3.891628124229713, loss: 0.45483618324522296\n",
      "Epochs: 736, w1: 7.388191122566447, w2: 1.404215444919555, bias: -3.8938156049836548, loss: 0.45478385462900994\n",
      "Epochs: 737, w1: 7.392784014120081, w2: 1.4046250649271677, bias: -3.8960001933526267, loss: 0.45473167412017085\n",
      "Epochs: 738, w1: 7.39737028771568, w2: 1.405034357449514, bias: -3.8981818944020317, loss: 0.4546796412251047\n",
      "Epochs: 739, w1: 7.401949956304175, w2: 1.4054433224779674, bias: -3.9003607131855627, loss: 0.4546277554521344\n",
      "Epochs: 740, w1: 7.406523032803183, w2: 1.4058519600055346, bias: -3.902536654745237, loss: 0.4545760163114995\n",
      "Epochs: 741, w1: 7.411089530097118, w2: 1.4062602700268472, bias: -3.9047097241114312, loss: 0.45452442331534654\n",
      "Epochs: 742, w1: 7.415649461037284, w2: 1.406668252538154, bias: -3.9068799263029144, loss: 0.4544729759777212\n",
      "Epochs: 743, w1: 7.420202838441988, w2: 1.4070759075373116, bias: -3.9090472663268825, loss: 0.45442167381455917\n",
      "Epochs: 744, w1: 7.424749675096634, w2: 1.407483235023777, bias: -3.9112117491789924, loss: 0.4543705163436788\n",
      "Epochs: 745, w1: 7.429289983753834, w2: 1.4078902349985982, bias: -3.9133733798433954, loss: 0.4543195030847714\n",
      "Epochs: 746, w1: 7.433823777133502, w2: 1.4082969074644074, bias: -3.9155321632927707, loss: 0.454268633559394\n",
      "Epochs: 747, w1: 7.4383510679229605, w2: 1.4087032524254113, bias: -3.9176881044883594, loss: 0.4542179072909599\n",
      "Epochs: 748, w1: 7.44287186877704, w2: 1.4091092698873835, bias: -3.9198412083799967, loss: 0.4541673238047317\n",
      "Epochs: 749, w1: 7.44738619231818, w2: 1.409514959857656, bias: -3.921991479906147, loss: 0.45411688262781186\n",
      "Epochs: 750, w1: 7.451894051136529, w2: 1.4099203223451116, bias: -3.924138923993935, loss: 0.45406658328913563\n",
      "Epochs: 751, w1: 7.456395457790046, w2: 1.4103253573601746, bias: -3.9262835455591794, loss: 0.454016425319462\n",
      "Epochs: 752, w1: 7.4608904248046, w2: 1.4107300649148036, bias: -3.928425349506427, loss: 0.4539664082513662\n",
      "Epochs: 753, w1: 7.465378964674069, w2: 1.411134445022483, bias: -3.9305643407289836, loss: 0.4539165316192307\n",
      "Epochs: 754, w1: 7.469861089860438, w2: 1.4115384976982144, bias: -3.932700524108947, loss: 0.45386679495923893\n",
      "Epochs: 755, w1: 7.474336812793902, w2: 1.4119422229585092, bias: -3.9348339045172405, loss: 0.4538171978093653\n",
      "Epochs: 756, w1: 7.478806145872959, w2: 1.4123456208213803, bias: -3.9369644868136437, loss: 0.4537677397093686\n",
      "Epochs: 757, w1: 7.483269101464511, w2: 1.4127486913063334, bias: -3.9390922758468263, loss: 0.4537184202007836\n",
      "Epochs: 758, w1: 7.4877256919039645, w2: 1.4131514344343599, bias: -3.941217276454379, loss: 0.4536692388269137\n",
      "Epochs: 759, w1: 7.492175929495321, w2: 1.413553850227928, bias: -3.943339493462846, loss: 0.45362019513282176\n",
      "Epochs: 760, w1: 7.4966198265112824, w2: 1.413955938710975, bias: -3.9454589316877575, loss: 0.45357128866532365\n",
      "Epochs: 761, w1: 7.501057395193341, w2: 1.4143576999088998, bias: -3.94757559593366, loss: 0.45352251897298035\n",
      "Epochs: 762, w1: 7.5054886477518785, w2: 1.414759133848554, bias: -3.9496894909941487, loss: 0.45347388560608937\n",
      "Epochs: 763, w1: 7.509913596366265, w2: 1.4151602405582344, bias: -3.9518006216518997, loss: 0.4534253881166785\n",
      "Epochs: 764, w1: 7.51433225318495, w2: 1.4155610200676754, bias: -3.9539089926787003, loss: 0.45337702605849645\n",
      "Epochs: 765, w1: 7.5187446303255605, w2: 1.4159614724080405, bias: -3.956014608835481, loss: 0.4533287989870066\n",
      "Epochs: 766, w1: 7.523150739874995, w2: 1.416361597611915, bias: -3.958117474872346, loss: 0.4532807064593786\n",
      "Epochs: 767, w1: 7.527550593889521, w2: 1.4167613957132976, bias: -3.960217595528605, loss: 0.453232748034482\n",
      "Epochs: 768, w1: 7.5319442043948674, w2: 1.4171608667475926, bias: -3.9623149755328044, loss: 0.45318492327287707\n",
      "Epochs: 769, w1: 7.536331583386317, w2: 1.4175600107516022, bias: -3.9644096196027565, loss: 0.45313723173680887\n",
      "Epochs: 770, w1: 7.540712742828803, w2: 1.4179588277635193, bias: -3.966501532445572, loss: 0.4530896729901988\n",
      "Epochs: 771, w1: 7.545087694657003, w2: 1.418357317822919, bias: -3.9685907187576897, loss: 0.4530422465986382\n",
      "Epochs: 772, w1: 7.549456450775429, w2: 1.4187554809707505, bias: -3.970677183224907, loss: 0.4529949521293799\n",
      "Epochs: 773, w1: 7.553819023058524, w2: 1.419153317249331, bias: -3.9727609305224107, loss: 0.45294778915133166\n",
      "Epochs: 774, w1: 7.558175423350753, w2: 1.4195508267023358, bias: -3.9748419653148073, loss: 0.4529007572350492\n",
      "Epochs: 775, w1: 7.562525663466695, w2: 1.4199480093747925, bias: -3.9769202922561524, loss: 0.4528538559527277\n",
      "Epochs: 776, w1: 7.566869755191134, w2: 1.4203448653130724, bias: -3.978995915989982, loss: 0.45280708487819565\n",
      "Epochs: 777, w1: 7.571207710279153, w2: 1.420741394564883, bias: -3.9810688411493413, loss: 0.4527604435869083\n",
      "Epochs: 778, w1: 7.575539540456223, w2: 1.4211375971792608, bias: -3.983139072356815, loss: 0.4527139316559383\n",
      "Epochs: 779, w1: 7.579865257418296, w2: 1.4215334732065632, bias: -3.9852066142245577, loss: 0.4526675486639707\n",
      "Epochs: 780, w1: 7.584184872831896, w2: 1.4219290226984616, bias: -3.9872714713543216, loss: 0.45262129419129554\n",
      "Epochs: 781, w1: 7.588498398334206, w2: 1.4223242457079328, bias: -3.9893336483374884, loss: 0.45257516781979973\n",
      "Epochs: 782, w1: 7.59280584553316, w2: 1.4227191422892527, bias: -3.9913931497550976, loss: 0.45252916913296115\n",
      "Epochs: 783, w1: 7.597107226007536, w2: 1.4231137124979882, bias: -3.9934499801778753, loss: 0.4524832977158413\n",
      "Epochs: 784, w1: 7.6014025513070385, w2: 1.42350795639099, bias: -3.9955041441662646, loss: 0.4524375531550785\n",
      "Epochs: 785, w1: 7.605691832952394, w2: 1.423901874026385, bias: -3.9975556462704533, loss: 0.45239193503888103\n",
      "Epochs: 786, w1: 7.609975082435439, w2: 1.4242954654635684, bias: -3.9996044910304045, loss: 0.4523464429570199\n",
      "Epochs: 787, w1: 7.614252311219204, w2: 1.4246887307631981, bias: -4.001650682975884, loss: 0.45230107650082246\n",
      "Epochs: 788, w1: 7.618523530738004, w2: 1.4250816699871853, bias: -4.003694226626491, loss: 0.45225583526316554\n",
      "Epochs: 789, w1: 7.622788752397532, w2: 1.4254742831986884, bias: -4.005735126491684, loss: 0.4522107188384687\n",
      "Epochs: 790, w1: 7.627047987574937, w2: 1.4258665704621052, bias: -4.007773387070812, loss: 0.45216572682268724\n",
      "Epochs: 791, w1: 7.631301247618917, w2: 1.426258531843066, bias: -4.009809012853141, loss: 0.452120858813306\n",
      "Epochs: 792, w1: 7.635548543849807, w2: 1.4266501674084264, bias: -4.011842008317885, loss: 0.45207611440933193\n",
      "Epochs: 793, w1: 7.639789887559663, w2: 1.4270414772262594, bias: -4.013872377934231, loss: 0.45203149321128877\n",
      "Epochs: 794, w1: 7.6440252900123475, w2: 1.4274324613658491, bias: -4.0159001261613705, loss: 0.4519869948212088\n",
      "Epochs: 795, w1: 7.64825476244362, w2: 1.4278231198976832, bias: -4.017925257448525, loss: 0.451942618842628\n",
      "Epochs: 796, w1: 7.652478316061218, w2: 1.4282134528934456, bias: -4.019947776234975, loss: 0.45189836488057794\n",
      "Epochs: 797, w1: 7.656695962044947, w2: 1.4286034604260098, bias: -4.021967686950088, loss: 0.4518542325415806\n",
      "Epochs: 798, w1: 7.660907711546761, w2: 1.4289931425694316, bias: -4.023984994013347, loss: 0.4518102214336409\n",
      "Epochs: 799, w1: 7.665113575690851, w2: 1.4293824993989417, bias: -4.025999701834376, loss: 0.45176633116624126\n",
      "Epochs: 800, w1: 7.66931356557373, w2: 1.4297715309909396, bias: -4.02801181481297, loss: 0.45172256135033406\n",
      "Epochs: 801, w1: 7.673507692264312, w2: 1.4301602374229856, bias: -4.0300213373391225, loss: 0.4516789115983363\n",
      "Epochs: 802, w1: 7.677695966804006, w2: 1.4305486187737946, bias: -4.03202827379305, loss: 0.4516353815241224\n",
      "Epochs: 803, w1: 7.681878400206787, w2: 1.4309366751232286, bias: -4.034032628545222, loss: 0.4515919707430191\n",
      "Epochs: 804, w1: 7.686055003459291, w2: 1.4313244065522903, bias: -4.0360344059563875, loss: 0.45154867887179756\n",
      "Epochs: 805, w1: 7.690225787520893, w2: 1.4317118131431157, bias: -4.038033610377603, loss: 0.4515055055286684\n",
      "Epochs: 806, w1: 7.6943907633237885, w2: 1.4320988949789677, bias: -4.040030246150258, loss: 0.4514624503332753\n",
      "Epochs: 807, w1: 7.698549941773079, w2: 1.4324856521442293, bias: -4.042024317606103, loss: 0.45141951290668825\n",
      "Epochs: 808, w1: 7.702703333746854, w2: 1.432872084724396, bias: -4.044015829067275, loss: 0.4513766928713976\n",
      "Epochs: 809, w1: 7.706850950096271, w2: 1.4332581928060704, bias: -4.046004784846327, loss: 0.4513339898513086\n",
      "Epochs: 810, w1: 7.7109928016456415, w2: 1.4336439764769542, bias: -4.047991189246254, loss: 0.4512914034717344\n",
      "Epochs: 811, w1: 7.715128899192506, w2: 1.434029435825842, bias: -4.049975046560514, loss: 0.45124893335939026\n",
      "Epochs: 812, w1: 7.7192592535077225, w2: 1.4344145709426148, bias: -4.0519563610730644, loss: 0.4512065791423881\n",
      "Epochs: 813, w1: 7.723383875335542, w2: 1.434799381918233, bias: -4.053935137058379, loss: 0.45116434045022963\n",
      "Epochs: 814, w1: 7.727502775393691, w2: 1.4351838688447298, bias: -4.055911378781481, loss: 0.45112221691380067\n",
      "Epochs: 815, w1: 7.731615964373452, w2: 1.435568031815205, bias: -4.057885090497966, loss: 0.4510802081653658\n",
      "Epochs: 816, w1: 7.735723452939745, w2: 1.4359518709238182, bias: -4.0598562764540285, loss: 0.4510383138385615\n",
      "Epochs: 817, w1: 7.739825251731205, w2: 1.4363353862657815, bias: -4.0618249408864875, loss: 0.4509965335683908\n",
      "Epochs: 818, w1: 7.743921371360263, w2: 1.4367185779373544, bias: -4.063791088022815, loss: 0.45095486699121756\n",
      "Epochs: 819, w1: 7.748011822413223, w2: 1.437101446035836, bias: -4.0657547220811585, loss: 0.45091331374476\n",
      "Epochs: 820, w1: 7.752096615450344, w2: 1.4374839906595593, bias: -4.067715847270369, loss: 0.4508718734680856\n",
      "Epochs: 821, w1: 7.7561757610059185, w2: 1.4378662119078847, bias: -4.069674467790026, loss: 0.4508305458016048\n",
      "Epochs: 822, w1: 7.760249269588349, w2: 1.4382481098811932, bias: -4.071630587830464, loss: 0.45078933038706576\n",
      "Epochs: 823, w1: 7.764317151680228, w2: 1.4386296846808806, bias: -4.073584211572795, loss: 0.4507482268675481\n",
      "Epochs: 824, w1: 7.768379417738414, w2: 1.4390109364093504, bias: -4.075535343188938, loss: 0.4507072348874575\n",
      "Epochs: 825, w1: 7.7724360781941115, w2: 1.4393918651700077, bias: -4.077483986841642, loss: 0.45066635409252\n",
      "Epochs: 826, w1: 7.776487143452947, w2: 1.4397724710672537, bias: -4.079430146684512, loss: 0.45062558412977655\n",
      "Epochs: 827, w1: 7.780532623895045, w2: 1.4401527542064783, bias: -4.081373826862033, loss: 0.4505849246475767\n",
      "Epochs: 828, w1: 7.784572529875109, w2: 1.4405327146940543, bias: -4.083315031509597, loss: 0.45054437529557423\n",
      "Epochs: 829, w1: 7.788606871722493, w2: 1.4409123526373315, bias: -4.085253764753527, loss: 0.45050393572472025\n",
      "Epochs: 830, w1: 7.792635659741281, w2: 1.4412916681446302, bias: -4.087190030711101, loss: 0.4504636055872584\n",
      "Epochs: 831, w1: 7.7966589042103625, w2: 1.4416706613252346, bias: -4.089123833490579, loss: 0.45042338453671943\n",
      "Epochs: 832, w1: 7.800676615383508, w2: 1.4420493322893875, bias: -4.091055177191225, loss: 0.45038327222791563\n",
      "Epochs: 833, w1: 7.8046888034894435, w2: 1.4424276811482837, bias: -4.0929840659033365, loss: 0.4503432683169349\n",
      "Epochs: 834, w1: 7.80869547873193, w2: 1.442805708014064, bias: -4.094910503708262, loss: 0.45030337246113616\n",
      "Epochs: 835, w1: 7.812696651289833, w2: 1.4431834129998091, bias: -4.096834494678432, loss: 0.450263584319143\n",
      "Epochs: 836, w1: 7.816692331317199, w2: 1.4435607962195336, bias: -4.098756042877379, loss: 0.45022390355083924\n",
      "Epochs: 837, w1: 7.820682528943335, w2: 1.44393785778818, bias: -4.100675152359764, loss: 0.4501843298173627\n",
      "Epochs: 838, w1: 7.824667254272875, w2: 1.4443145978216128, bias: -4.102591827171402, loss: 0.450144862781101\n",
      "Epochs: 839, w1: 7.828646517385858, w2: 1.4446910164366122, bias: -4.104506071349284, loss: 0.45010550210568473\n",
      "Epochs: 840, w1: 7.832620328337802, w2: 1.4450671137508688, bias: -4.1064178889216, loss: 0.4500662474559837\n",
      "Epochs: 841, w1: 7.836588697159778, w2: 1.4454428898829772, bias: -4.108327283907768, loss: 0.4500270984981005\n",
      "Epochs: 842, w1: 7.84055163385848, w2: 1.4458183449524302, bias: -4.110234260318451, loss: 0.4499880548993662\n",
      "Epochs: 843, w1: 7.844509148416303, w2: 1.4461934790796132, bias: -4.112138822155588, loss: 0.44994911632833473\n",
      "Epochs: 844, w1: 7.848461250791409, w2: 1.4465682923857976, bias: -4.114040973412412, loss: 0.4499102824547775\n",
      "Epochs: 845, w1: 7.852407950917808, w2: 1.4469427849931364, bias: -4.115940718073477, loss: 0.4498715529496788\n",
      "Epochs: 846, w1: 7.856349258705422, w2: 1.4473169570246573, bias: -4.117838060114682, loss: 0.44983292748522974\n",
      "Epochs: 847, w1: 7.860285184040164, w2: 1.4476908086042573, bias: -4.119733003503291, loss: 0.4497944057348246\n",
      "Epochs: 848, w1: 7.864215736784003, w2: 1.4480643398566968, bias: -4.12162555219796, loss: 0.4497559873730543\n",
      "Epochs: 849, w1: 7.868140926775042, w2: 1.4484375509075946, bias: -4.12351571014876, loss: 0.4497176720757023\n",
      "Epochs: 850, w1: 7.872060763827585, w2: 1.4488104418834213, bias: -4.125403481297197, loss: 0.449679459519739\n",
      "Epochs: 851, w1: 7.875975257732208, w2: 1.4491830129114942, bias: -4.12728886957624, loss: 0.44964134938331723\n",
      "Epochs: 852, w1: 7.879884418255835, w2: 1.4495552641199716, bias: -4.129171878910343, loss: 0.44960334134576707\n",
      "Epochs: 853, w1: 7.883788255141801, w2: 1.4499271956378474, bias: -4.131052513215463, loss: 0.4495654350875903\n",
      "Epochs: 854, w1: 7.887686778109927, w2: 1.4502988075949452, bias: -4.132930776399093, loss: 0.44952763029045695\n",
      "Epochs: 855, w1: 7.89157999685659, w2: 1.4506701001219127, bias: -4.134806672360272, loss: 0.44948992663719844\n",
      "Epochs: 856, w1: 7.8954679210547924, w2: 1.4510410733502168, bias: -4.13668020498962, loss: 0.4494523238118047\n",
      "Epochs: 857, w1: 7.899350560354228, w2: 1.4514117274121374, bias: -4.138551378169355, loss: 0.44941482149941747\n",
      "Epochs: 858, w1: 7.9032279243813575, w2: 1.4517820624407627, bias: -4.1404201957733155, loss: 0.449377419386327\n",
      "Epochs: 859, w1: 7.907100022739473, w2: 1.4521520785699829, bias: -4.142286661666984, loss: 0.4493401171599658\n",
      "Epochs: 860, w1: 7.91096686500877, w2: 1.4525217759344855, bias: -4.144150779707509, loss: 0.4493029145089056\n",
      "Epochs: 861, w1: 7.914828460746412, w2: 1.4528911546697498, bias: -4.146012553743731, loss: 0.4492658111228508\n",
      "Epochs: 862, w1: 7.918684819486603, w2: 1.453260214912041, bias: -4.147871987616199, loss: 0.4492288066926346\n",
      "Epochs: 863, w1: 7.922535950740654, w2: 1.4536289567984058, bias: -4.149729085157198, loss: 0.4491919009102144\n",
      "Epochs: 864, w1: 7.926381863997051, w2: 1.4539973804666662, bias: -4.151583850190769, loss: 0.4491550934686667\n",
      "Epochs: 865, w1: 7.930222568721522, w2: 1.4543654860554147, bias: -4.15343628653273, loss: 0.4491183840621829\n",
      "Epochs: 866, w1: 7.934058074357106, w2: 1.454733273704009, bias: -4.155286397990702, loss: 0.4490817723860637\n",
      "Epochs: 867, w1: 7.9378883903242174, w2: 1.4551007435525671, bias: -4.157134188364126, loss: 0.44904525813671586\n",
      "Epochs: 868, w1: 7.941713526020719, w2: 1.4554678957419613, bias: -4.15897966144429, loss: 0.4490088410116465\n",
      "Epochs: 869, w1: 7.945533490821981, w2: 1.4558347304138135, bias: -4.160822821014347, loss: 0.44897252070945837\n",
      "Epochs: 870, w1: 7.949348294080954, w2: 1.4562012477104902, bias: -4.162663670849339, loss: 0.4489362969298463\n",
      "Epochs: 871, w1: 7.953157945128231, w2: 1.4565674477750972, bias: -4.164502214716219, loss: 0.4489001693735922\n",
      "Epochs: 872, w1: 7.956962453272116, w2: 1.4569333307514742, bias: -4.166338456373871, loss: 0.44886413774255973\n",
      "Epochs: 873, w1: 7.960761827798689, w2: 1.4572988967841902, bias: -4.168172399573133, loss: 0.44882820173969123\n",
      "Epochs: 874, w1: 7.964556077971872, w2: 1.4576641460185384, bias: -4.170004048056819, loss: 0.44879236106900183\n",
      "Epochs: 875, w1: 7.968345213033492, w2: 1.458029078600531, bias: -4.171833405559737, loss: 0.44875661543557627\n",
      "Epochs: 876, w1: 7.972129242203354, w2: 1.4583936946768938, bias: -4.173660475808717, loss: 0.44872096454556315\n",
      "Epochs: 877, w1: 7.975908174679295, w2: 1.4587579943950624, bias: -4.175485262522626, loss: 0.44868540810617186\n",
      "Epochs: 878, w1: 7.979682019637255, w2: 1.4591219779031759, bias: -4.177307769412392, loss: 0.44864994582566686\n",
      "Epochs: 879, w1: 7.983450786231343, w2: 1.4594856453500726, bias: -4.179128000181026, loss: 0.44861457741336463\n",
      "Epochs: 880, w1: 7.987214483593897, w2: 1.4598489968852855, bias: -4.180945958523641, loss: 0.44857930257962786\n",
      "Epochs: 881, w1: 7.990973120835553, w2: 1.4602120326590364, bias: -4.182761648127476, loss: 0.4485441210358621\n",
      "Epochs: 882, w1: 7.994726707045301, w2: 1.4605747528222324, bias: -4.1845750726719135, loss: 0.4485090324945118\n",
      "Epochs: 883, w1: 7.99847525129056, w2: 1.4609371575264594, bias: -4.186386235828503, loss: 0.44847403666905455\n",
      "Epochs: 884, w1: 8.00221876261723, w2: 1.4612992469239785, bias: -4.188195141260982, loss: 0.4484391332739982\n",
      "Epochs: 885, w1: 8.005957250049764, w2: 1.4616610211677212, bias: -4.190001792625295, loss: 0.4484043220248758\n",
      "Epochs: 886, w1: 8.009690722591225, w2: 1.462022480411284, bias: -4.191806193569616, loss: 0.4483696026382418\n",
      "Epochs: 887, w1: 8.013419189223352, w2: 1.4623836248089244, bias: -4.193608347734369, loss: 0.44833497483166745\n",
      "Epochs: 888, w1: 8.017142658906623, w2: 1.462744454515555, bias: -4.195408258752245, loss: 0.4483004383237368\n",
      "Epochs: 889, w1: 8.020861140580315, w2: 1.4631049696867404, bias: -4.19720593024823, loss: 0.4482659928340429\n",
      "Epochs: 890, w1: 8.02457464316257, w2: 1.4634651704786912, bias: -4.199001365839618, loss: 0.4482316380831826\n",
      "Epochs: 891, w1: 8.028283175550449, w2: 1.46382505704826, bias: -4.200794569136037, loss: 0.44819737379275393\n",
      "Epochs: 892, w1: 8.031986746620005, w2: 1.4641846295529368, bias: -4.202585543739465, loss: 0.44816319968534996\n",
      "Epochs: 893, w1: 8.035685365226335, w2: 1.464543888150844, bias: -4.204374293244253, loss: 0.4481291154845568\n",
      "Epochs: 894, w1: 8.039379040203649, w2: 1.464902833000732, bias: -4.2061608212371455, loss: 0.4480951209149484\n",
      "Epochs: 895, w1: 8.043067780365321, w2: 1.4652614642619752, bias: -4.207945131297298, loss: 0.44806121570208207\n",
      "Epochs: 896, w1: 8.046751594503963, w2: 1.4656197820945664, bias: -4.209727226996299, loss: 0.44802739957249554\n",
      "Epochs: 897, w1: 8.050430491391472, w2: 1.4659777866591133, bias: -4.211507111898192, loss: 0.44799367225370257\n",
      "Epochs: 898, w1: 8.054104479779104, w2: 1.4663354781168332, bias: -4.213284789559491, loss: 0.44796003347418795\n",
      "Epochs: 899, w1: 8.057773568397524, w2: 1.4666928566295492, bias: -4.215060263529205, loss: 0.44792648296340504\n",
      "Epochs: 900, w1: 8.06143776595687, w2: 1.4670499223596853, bias: -4.216833537348852, loss: 0.4478930204517708\n",
      "Epochs: 901, w1: 8.065097081146812, w2: 1.4674066754702624, bias: -4.218604614552486, loss: 0.44785964567066244\n",
      "Epochs: 902, w1: 8.068751522636614, w2: 1.4677631161248934, bias: -4.220373498666713, loss: 0.44782635835241247\n",
      "Epochs: 903, w1: 8.072401099075192, w2: 1.468119244487779, bias: -4.222140193210707, loss: 0.4477931582303063\n",
      "Epochs: 904, w1: 8.076045819091172, w2: 1.4684750607237043, bias: -4.223904701696239, loss: 0.44776004503857647\n",
      "Epochs: 905, w1: 8.079685691292951, w2: 1.4688305649980322, bias: -4.225667027627686, loss: 0.44772701851240115\n",
      "Epochs: 906, w1: 8.083320724268756, w2: 1.4691857574767018, bias: -4.2274271745020595, loss: 0.4476940783878979\n",
      "Epochs: 907, w1: 8.086950926586699, w2: 1.469540638326222, bias: -4.229185145809018, loss: 0.447661224402121\n",
      "Epochs: 908, w1: 8.090576306794839, w2: 1.4698952077136682, bias: -4.230940945030891, loss: 0.44762845629305803\n",
      "Epochs: 909, w1: 8.094196873421243, w2: 1.4702494658066783, bias: -4.232694575642695, loss: 0.4475957737996252\n",
      "Epochs: 910, w1: 8.097812634974037, w2: 1.4706034127734473, bias: -4.234446041112156, loss: 0.4475631766616632\n",
      "Epochs: 911, w1: 8.10142359994147, w2: 1.4709570487827248, bias: -4.236195344899725, loss: 0.44753066461993546\n",
      "Epochs: 912, w1: 8.105029776791966, w2: 1.4713103740038094, bias: -4.237942490458602, loss: 0.44749823741612166\n",
      "Epochs: 913, w1: 8.108631173974189, w2: 1.471663388606545, bias: -4.23968748123475, loss: 0.44746589479281645\n",
      "Epochs: 914, w1: 8.112227799917093, w2: 1.472016092761317, bias: -4.241430320666916, loss: 0.44743363649352386\n",
      "Epochs: 915, w1: 8.115819663029987, w2: 1.4723684866390478, bias: -4.243171012186652, loss: 0.4474014622626549\n",
      "Epochs: 916, w1: 8.11940677170258, w2: 1.4727205704111925, bias: -4.24490955921833, loss: 0.4473693718455229\n",
      "Epochs: 917, w1: 8.122989134305051, w2: 1.4730723442497355, bias: -4.246645965179164, loss: 0.44733736498834065\n",
      "Epochs: 918, w1: 8.126566759188096, w2: 1.473423808327186, bias: -4.248380233479228, loss: 0.447305441438216\n",
      "Epochs: 919, w1: 8.13013965468299, w2: 1.473774962816574, bias: -4.2501123675214725, loss: 0.447273600943149\n",
      "Epochs: 920, w1: 8.133707829101642, w2: 1.4741258078914463, bias: -4.2518423707017465, loss: 0.4472418432520277\n",
      "Epochs: 921, w1: 8.137271290736647, w2: 1.4744763437258628, bias: -4.253570246408814, loss: 0.44721016811462433\n",
      "Epochs: 922, w1: 8.140830047861346, w2: 1.474826570494392, bias: -4.255295998024373, loss: 0.4471785752815926\n",
      "Epochs: 923, w1: 8.144384108729882, w2: 1.475176488372107, bias: -4.257019628923074, loss: 0.4471470645044638\n",
      "Epochs: 924, w1: 8.147933481577253, w2: 1.475526097534583, bias: -4.258741142472539, loss: 0.4471156355356422\n",
      "Epochs: 925, w1: 8.151478174619365, w2: 1.4758753981578911, bias: -4.26046054203338, loss: 0.4470842881284035\n",
      "Epochs: 926, w1: 8.155018196053096, w2: 1.4762243904185968, bias: -4.262177830959215, loss: 0.44705302203688907\n",
      "Epochs: 927, w1: 8.158553554056342, w2: 1.4765730744937537, bias: -4.263893012596688, loss: 0.4470218370161044\n",
      "Epochs: 928, w1: 8.162084256788074, w2: 1.4769214505609018, bias: -4.2656060902854875, loss: 0.4469907328219142\n",
      "Epochs: 929, w1: 8.165610312388393, w2: 1.4772695187980625, bias: -4.2673170673583645, loss: 0.44695970921103995\n",
      "Epochs: 930, w1: 8.169131728978588, w2: 1.4776172793837348, bias: -4.2690259471411505, loss: 0.4469287659410558\n",
      "Epochs: 931, w1: 8.172648514661182, w2: 1.4779647324968923, bias: -4.270732732952775, loss: 0.44689790277038527\n",
      "Epochs: 932, w1: 8.176160677519993, w2: 1.4783118783169786, bias: -4.272437428105283, loss: 0.446867119458298\n",
      "Epochs: 933, w1: 8.179668225620187, w2: 1.4786587170239038, bias: -4.274140035903855, loss: 0.44683641576490574\n",
      "Epochs: 934, w1: 8.183171167008327, w2: 1.4790052487980412, bias: -4.275840559646823, loss: 0.44680579145116006\n",
      "Epochs: 935, w1: 8.18666950971243, w2: 1.4793514738202227, bias: -4.277539002625687, loss: 0.44677524627884785\n",
      "Epochs: 936, w1: 8.190163261742024, w2: 1.479697392271736, bias: -4.279235368125138, loss: 0.44674478001058854\n",
      "Epochs: 937, w1: 8.193652431088188, w2: 1.4800430043343207, bias: -4.28092965942307, loss: 0.4467143924098309\n",
      "Epochs: 938, w1: 8.19713702572362, w2: 1.480388310190164, bias: -4.282621879790601, loss: 0.4466840832408492\n",
      "Epochs: 939, w1: 8.200617053602684, w2: 1.480733310021898, bias: -4.284312032492088, loss: 0.4466538522687401\n",
      "Epochs: 940, w1: 8.204092522661458, w2: 1.4810780040125957, bias: -4.286000120785147, loss: 0.4466236992594194\n",
      "Epochs: 941, w1: 8.207563440817792, w2: 1.4814223923457672, bias: -4.2876861479206685, loss: 0.4465936239796187\n",
      "Epochs: 942, w1: 8.211029815971356, w2: 1.4817664752053563, bias: -4.289370117142838, loss: 0.44656362619688256\n",
      "Epochs: 943, w1: 8.214491656003698, w2: 1.4821102527757373, bias: -4.291052031689149, loss: 0.4465337056795642\n",
      "Epochs: 944, w1: 8.217948968778291, w2: 1.4824537252417105, bias: -4.292731894790424, loss: 0.44650386219682336\n",
      "Epochs: 945, w1: 8.221401762140584, w2: 1.4827968927884998, bias: -4.294409709670829, loss: 0.4464740955186221\n",
      "Epochs: 946, w1: 8.224850043918057, w2: 1.4831397556017485, bias: -4.2960854795478935, loss: 0.4464444054157228\n",
      "Epochs: 947, w1: 8.22829382192027, w2: 1.4834823138675162, bias: -4.2977592076325255, loss: 0.4464147916596836\n",
      "Epochs: 948, w1: 8.231733103938913, w2: 1.4838245677722748, bias: -4.299430897129029, loss: 0.446385254022856\n",
      "Epochs: 949, w1: 8.235167897747862, w2: 1.4841665175029055, bias: -4.3011005512351215, loss: 0.44635579227838185\n",
      "Epochs: 950, w1: 8.238598211103225, w2: 1.4845081632466957, bias: -4.302768173141951, loss: 0.4463264062001896\n",
      "Epochs: 951, w1: 8.242024051743392, w2: 1.4848495051913346, bias: -4.304433766034112, loss: 0.4462970955629913\n",
      "Epochs: 952, w1: 8.245445427389091, w2: 1.485190543524911, bias: -4.306097333089665, loss: 0.44626786014228015\n",
      "Epochs: 953, w1: 8.248862345743433, w2: 1.485531278435909, bias: -4.307758877480148, loss: 0.4462386997143262\n",
      "Epochs: 954, w1: 8.252274814491964, w2: 1.4858717101132044, bias: -4.309418402370601, loss: 0.44620961405617443\n",
      "Epochs: 955, w1: 8.255682841302715, w2: 1.486211838746063, bias: -4.311075910919575, loss: 0.4461806029456408\n",
      "Epochs: 956, w1: 8.259086433826251, w2: 1.4865516645241352, bias: -4.312731406279155, loss: 0.44615166616130947\n",
      "Epochs: 957, w1: 8.262485599695722, w2: 1.4868911876374546, bias: -4.314384891594971, loss: 0.44612280348252986\n",
      "Epochs: 958, w1: 8.265880346526913, w2: 1.4872304082764332, bias: -4.316036370006219, loss: 0.4460940146894139\n",
      "Epochs: 959, w1: 8.269270681918291, w2: 1.4875693266318588, bias: -4.317685844645676, loss: 0.4460652995628319\n",
      "Epochs: 960, w1: 8.272656613451055, w2: 1.487907942894892, bias: -4.319333318639716, loss: 0.4460366578844107\n",
      "Epochs: 961, w1: 8.276038148689183, w2: 1.4882462572570625, bias: -4.320978795108326, loss: 0.44600808943653036\n",
      "Epochs: 962, w1: 8.279415295179488, w2: 1.488584269910266, bias: -4.3226222771651255, loss: 0.44597959400232057\n",
      "Epochs: 963, w1: 8.282788060451658, w2: 1.4889219810467613, bias: -4.324263767917378, loss: 0.4459511713656582\n",
      "Epochs: 964, w1: 8.286156452018309, w2: 1.4892593908591667, bias: -4.325903270466012, loss: 0.4459228213111647\n",
      "Epochs: 965, w1: 8.289520477375033, w2: 1.489596499540457, bias: -4.327540787905632, loss: 0.445894543624202\n",
      "Epochs: 966, w1: 8.292880144000444, w2: 1.4899333072839602, bias: -4.329176323324542, loss: 0.44586633809087106\n",
      "Epochs: 967, w1: 8.296235459356229, w2: 1.490269814283355, bias: -4.330809879804754, loss: 0.44583820449800765\n",
      "Epochs: 968, w1: 8.299586430887194, w2: 1.490606020732667, bias: -4.332441460422008, loss: 0.4458101426331801\n",
      "Epochs: 969, w1: 8.302933066021312, w2: 1.4909419268262658, bias: -4.334071068245788, loss: 0.4457821522846863\n",
      "Epochs: 970, w1: 8.306275372169772, w2: 1.491277532758862, bias: -4.335698706339339, loss: 0.44575423324155045\n",
      "Epochs: 971, w1: 8.309613356727022, w2: 1.4916128387255043, bias: -4.3373243777596775, loss: 0.4457263852935211\n",
      "Epochs: 972, w1: 8.312947027070821, w2: 1.491947844921576, bias: -4.338948085557615, loss: 0.44569860823106705\n",
      "Epochs: 973, w1: 8.316276390562287, w2: 1.492282551542792, bias: -4.340569832777767, loss: 0.44567090184537556\n",
      "Epochs: 974, w1: 8.319601454545936, w2: 1.4926169587851965, bias: -4.342189622458576, loss: 0.44564326592834935\n",
      "Epochs: 975, w1: 8.322922226349736, w2: 1.4929510668451593, bias: -4.343807457632319, loss: 0.4456157002726027\n",
      "Epochs: 976, w1: 8.326238713285154, w2: 1.4932848759193733, bias: -4.345423341325128, loss: 0.44558820467146015\n",
      "Epochs: 977, w1: 8.329550922647195, w2: 1.4936183862048509, bias: -4.347037276557009, loss: 0.4455607789189528\n",
      "Epochs: 978, w1: 8.33285886171446, w2: 1.4939515978989213, bias: -4.348649266341848, loss: 0.445533422809816\n",
      "Epochs: 979, w1: 8.336162537749178, w2: 1.4942845111992282, bias: -4.350259313687437, loss: 0.4455061361394859\n",
      "Epochs: 980, w1: 8.339461957997266, w2: 1.4946171263037262, bias: -4.351867421595482, loss: 0.44547891870409745\n",
      "Epochs: 981, w1: 8.342757129688362, w2: 1.4949494434106778, bias: -4.3534735930616195, loss: 0.4454517703004812\n",
      "Epochs: 982, w1: 8.34604806003588, w2: 1.4952814627186513, bias: -4.3550778310754374, loss: 0.4454246907261607\n",
      "Epochs: 983, w1: 8.349334756237054, w2: 1.4956131844265168, bias: -4.356680138620485, loss: 0.4453976797793499\n",
      "Epochs: 984, w1: 8.35261722547298, w2: 1.4959446087334445, bias: -4.358280518674288, loss: 0.44537073725895004\n",
      "Epochs: 985, w1: 8.35589547490866, w2: 1.496275735838901, bias: -4.359878974208368, loss: 0.4453438629645474\n",
      "Epochs: 986, w1: 8.359169511693056, w2: 1.4966065659426468, bias: -4.361475508188255, loss: 0.4453170566964106\n",
      "Epochs: 987, w1: 8.362439342959124, w2: 1.496937099244734, bias: -4.3630701235735, loss: 0.4452903182554875\n",
      "Epochs: 988, w1: 8.365704975823869, w2: 1.4972673359455024, bias: -4.364662823317698, loss: 0.4452636474434028\n",
      "Epochs: 989, w1: 8.368966417388378, w2: 1.4975972762455776, bias: -4.366253610368494, loss: 0.44523704406245534\n",
      "Epochs: 990, w1: 8.372223674737876, w2: 1.4979269203458678, bias: -4.367842487667604, loss: 0.44521050791561584\n",
      "Epochs: 991, w1: 8.375476754941761, w2: 1.4982562684475615, bias: -4.369429458150828, loss: 0.44518403880652363\n",
      "Epochs: 992, w1: 8.378725665053658, w2: 1.4985853207521245, bias: -4.371014524748064, loss: 0.44515763653948465\n",
      "Epochs: 993, w1: 8.381970412111452, w2: 1.4989140774612968, bias: -4.372597690383326, loss: 0.4451313009194679\n",
      "Epochs: 994, w1: 8.38521100313734, w2: 1.4992425387770907, bias: -4.374178957974756, loss: 0.4451050317521045\n",
      "Epochs: 995, w1: 8.38844744513787, w2: 1.4995707049017872, bias: -4.375758330434639, loss: 0.4450788288436831\n",
      "Epochs: 996, w1: 8.391679745103993, w2: 1.4998985760379344, bias: -4.377335810669418, loss: 0.4450526920011489\n",
      "Epochs: 997, w1: 8.394907910011092, w2: 1.500226152388344, bias: -4.378911401579712, loss: 0.4450266210321001\n",
      "Epochs: 998, w1: 8.398131946819039, w2: 1.5005534341560887, bias: -4.380485106060326, loss: 0.4450006157447861\n",
      "Epochs: 999, w1: 8.40135186247223, w2: 1.5008804215445, bias: -4.382056927000267, loss: 0.44497467594810486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(8.40135186247223),\n",
       " np.float64(1.5008804215445),\n",
       " np.float64(-4.382056927000267))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(X_train_scaled['age'], X_train_scaled['affordibility'], y_train, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132c89b5-2c93-4882-b1ee-42d5ac81b9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
